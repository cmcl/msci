\documentclass{beamer}

\usepackage[latin1]{inputenc}
\usepackage{cmll}
\usepackage{lstmacros}
\usepackage{graphicx}
\usepackage{array}
\usepackage{subfigure}
\usepackage{amsmath}
\usepackage{comment}
\usepackage{etoolbox}
\usepackage{tikz}
\usetikzlibrary{arrows,positioning}
\usepackage[style=alphabetic,natbib=true]{biblatex}

\usetheme{Warsaw}

\newtoggle{tdlp}
\toggletrue{tdlp}
\input{propmacros}
\newcommand{\altt}{~|~}

\let\oldframetitle\frametitle
\renewcommand{\frametitle}[1]{
  \oldframetitle{#1}\vspace{-3.5cm}
}

\title[Project Presentation]{Propositions as Sessions, Mechanically}
\author{Craig McLaughlin}
\institute{University Of Glasgow}
\date{\today}

\begin{document}

\begin{frame}
\titlepage
\end{frame}

\section{Preamble}

\begin{comment}
today i am going to talk about a formalisation effort based on an existing
type system whose properties have previously only been studied
informally. first in order to motivate the previous and current work i shall
make two general observations here. one: distributed communication systems are
becoming increasingly prevalent in modern society. two: the correct
functioning of these systems hinges on the protocol between any two
communicating agents to be well-defined and correctly implemented.
\end{comment}

\begin{frame}
\oldframetitle{Session Types}
\begin{math}
  \begin{array}{cccc}
    S & \bnf  & \inpt{T}{S} & \mbox{receive value of type T, continue as S}\\
      & \altt & \outpt{T}{S} & \mbox{send value of type T, continue as S}\\
      & \altt & \Branch{l_i}{S_i}{i\in I} &
                           \mbox{offer between $|I|$ alternatives}\\
      & \altt & \Choice{l_i}{S_i}{i\in I} &
                           \mbox{choose between $|I|$ alternatives}\\
      & \altt & \mbox{\lstinline{end}} & \mbox{terminate session}\\
 \dual{S} & \bnf & \mbox{dual of S}\\
 \dual{(\inpt{T}{S})} & \bnf & \outpt{T}{\dual{S}}\\
 \dual{\Branch{l_i}{S_i}{i\in I}} & \bnf & \Choice{l_i}{\dual{S_i}}{i\in I}\\
            \vdots                & \cdots & \vdots
 \end{array}
\end{math}
\end{frame}

\begin{comment}
one approach to achieve such correctness guarantees is by using binary session
types. [INTRODUCE BINARY SESSION TYPES HERE]. specifying a communication
protocol then involves providing mutual dual types to the communicating
parties. [a simple example with two processes is displayed].
\end{comment}

\begin{frame}
\frametitle{Motivation}
Hand-written (informal) proofs $=$ Error-prone $+$ Difficult to update
\end{frame}

\begin{comment}
there has been a lot of activity in this area producing a variety of different
session-based type systems. many systems build on top of previous work adding
more complex features such as asynchronous, polymorphic and recursive session
types. extending informal proofs is error-prone and difficult because it is
not always clear which parts of a system's metatheory is affected by a
change. a formalised system would reduce likelihood of errors in the proofs
and aid extension since the theorem prover would highlight changes to the
metatheory
\end{comment}

\begin{frame}
\frametitle{System Overview}
CP $=$ process calculus with operators from classical linear logic

GV $=$ functional language with session types

GV $\to$ CP translation
\end{frame}

\begin{comment}
the formalisation i present here is an encoding of a system in the Coq proof
assistant. it is based on a two-tier system providing a logical foundation for
understanding session types. A high-level overview of the system is as
follows: we have a process calculus CP with operators from classical linear
logic, a high-level functional language GV with session types, and a
translation from GV to CP which interprets operators in classical linear logic
as session types.
\end{comment}

\begin{frame}
\frametitle{CP Propositions}
\begin{math}
\begin{array}{rclc}
    \tp{A,B,C} & \bnf
          & \tp{A \otimes B} & \key{times: output A then behave as B}\\
          & \altt & \tp{A \parr B} & \key{par: input A then behave as B}\\
          & \altt & \cdots
\end{array}
\end{math}

For all propositions $A$, $\dualbt{(\dualbt{A})} = A$ (negation is an
involution)
\end{frame}

\begin{comment}
by classical linear logic i mean a logic where negation is an involution which
restricts the use of certain rules on resources, namely that all linear
resources must be used (corresponding to prohibiting weakening) and that one
cannot duplicate a linear resource (corresponding to contraction). some typing
rules for the CP calculus are presented as they appear in the Coq encoding
(note that they are very similar to their informal counterparts). the
interpretation of tensor product is output of A and continue as B. The dual of
this is input of A and continue as the negation of B. Thus negation in
classical linear logic corresponds to session duality.
\end{comment}

\section{Formalisation}

\begin{frame}
\frametitle{Goals}
\begin{itemize}
\item Reuse where possible
\item Minimise difference between informal/formal variants
\item Avoid known pitfalls
\end{itemize}
\end{frame}

\begin{comment}
The encoding follows practices in formalising programming language metatheory
with a principal design goal of reusing existing libraries from previous
developments. Additionally, I want to keep as close a correspondence as
possible between the development and the pen-and-paper presentation in order
to mitigate questions of adequacy, you know, whether the formal system is what
you intended to formalise. And lastly, I aimed to exploit the features of the
Coq system without over complicating the development such as taking careful
consideration over representation choices.
\end{comment}

\begin{frame}
\oldframetitle{Preliminaries}
\begin{itemize}
\item Locally Nameless
  \begin{itemize}
  \item Avoids variable capture
  \item de Bruijn indices for bound variables
    ($\lambda~(\lambda~1) \equiv \lambda x. \lambda y. x$)
  \end{itemize}
\item Cofinite Quantification
  \begin{itemize}
  \item stronger induction principle
  \item
    \begin{math}
    \begin{array}{lcl}
      \mbox{Exists-Fresh} & & \mbox{Cofinite}\\
      \inference{
        x \notin FV(N) &
        \Tp{\Gamma \comma \Tmof{x}T} \Tpvdash \Tmof{N^x}\Tp{U}
      }{}{
        \Tp{\Gamma} \Tpvdash \Tmof{abs~N}\Tp{T \to U}
      }
    & \mbox{vs}. &
      \inference{
        \forall x \notin L.
        (\Tp{\Gamma \comma \Tmof{x}T} \Tpvdash \Tmof{N^x}\Tp{U})
      }{}{
        \Tp{\Gamma} \Tpvdash \Tmof{abs~N}\Tp{T \to U}
      }
    \end{array}
    \end{math}
  \end{itemize}
\item Metatheory library for representation
\end{itemize}
\end{frame}

\begin{comment}
one of the key issues when formalising programming language metatheory is how
to represent variables both bound and free. I chose the locally nameless
representation which separates bound and free variables into distinct
entities. Thus it avoids the variable capture problem in contrast to other
approaches.

In this approach, a de Bruijn index is a number used to represent a bound
variable which indicates the position of its binder (starting from zero for
the innermost binder).

Constructs with binders have to open the term with a free variable and this
requires some technique for handling freshness of the opening variable. I
chose to adopt the cofinite quantification approach which allows to exclude a
finite set of names from consideration. in contrast to the sometimes weaker
notion of a single sufficiently fresh name
\end{comment}

\subsection{CP}

\begin{frame}[fragile]
\oldframetitle{CP Rules: Formal vs. Informal Comparison}
\begin{tabular}{lc}
\begin{coqp}
Inductive cp_rule : proc -> penv -> Prop :=
  | $\cdots$
  | cp_cut :
      forall (L:atoms) P Q A $\Gamma$ $\Delta$P $\Delta$Q
             (PER: Permutation $\Gamma$ ($\Delta$P ++ $\Delta$Q))
             (CPP: forall (x:atom) (NL: x $\notin$ L),
                     (open_proc P x) $\tpcp$ (x $\sim$ A) ++ $\Delta$P)
             (CPQ: forall (x:atom) (NL: x $\notin$ L),
                (open_proc Q x) $\tpcp$ (x $\sim$ $\dualbt{A}$) ++ $\Delta$Q),
        $\nu$ A.(P $\mid$ Q) $\tpcp$ $\Gamma$
  | $\cdots$
\end{coqp} &
\begin{math}
\colored
\inference{
  \tm{P} \tpvdash \tp{\Gamma \comma \tmof{x}A}
  &
  \tm{Q} \tpvdash \tp{\Delta \comma \tmof{x}\dualbt{A}}
}{}{
  \tm{\nu x \of{A}.(P \mid Q)} \tpvdash \tp{\Gamma \comma \Delta}
}
\end{math}
\end{tabular}

%% \begin{coqp}
%% Inductive cp_rule : proc -> penv -> Prop :=
%%   | $\cdots$
%%   | cp_cut :
%%       forall (L:atoms) P Q A $\Gamma$ $\Delta$P $\Delta$Q
%%              (PER: Permutation $\Gamma$ ($\Delta$P ++ $\Delta$Q))
%%              (CPP: forall (x:atom) (NL: x $\notin$ L),
%%                      (open_proc P x) $\tpcp$ (x $\sim$ A) ++ $\Delta$P)
%%              (CPQ: forall (x:atom) (NL: x $\notin$ L),
%%                 (open_proc Q x) $\tpcp$ (x $\sim$ $\dualbt{A}$) ++ $\Delta$Q),
%%         $\nu$ A.(P $\mid$ Q) $\tpcp$ $\Gamma$
%%   | $\cdots$
%% \end{coqp}
\end{frame}

\begin{comment}
lets take a look at cp's typing rules. here we used a well typed relation on
the process terms of cp. we require additional assumptions for environment
ordering and more attention is paid to the opening of subprocesses. this
presents the informal and formal definitions of cut. There is no overhead when
introducing binders to the subprocesses or for environment ordering, but apart
from these representation issues the rules look similar which could assist the
uptake of such formal tools by programming language researchers.
\end{comment}

\defverbatim[colored]\subred{
\begin{coq}
Theorem proc_sub_red:
  forall $\Gamma$ P Q
         (WT: P $\tpvdash_{cp}$ $\Gamma$)
         (RED: P $\becomes$ Q),
    Q $\tpvdash_{cp}$ $\Gamma$.
\end{coq}
}

\begin{frame}
\oldframetitle{Subject Reduction in CP}
\subred
\begin{itemize}
\item {\fontsize{6}{7.2}\selectfont blah one}
\item blah two
\item blah three
\item blah four
\item blah five
\item blah six
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Subject Reduction in CP}
\[\colored
\begin{array}{c}
\mbox{Subject reduction} = \left\{ \begin{array}{ll}
                                   \mbox{Principal cut reductions}~(\beta)\\
                                   \mbox{Commuting Conversions}~(\kappa)
                                   \end{array} \right.
\\~\\
(\kappa_{\otimes1}) \quad
\tm{\nu z\Of{C}.(x[y].(P \mid Q) \mid R)}
\quad \becomes \hfill
\hfill \tm{x[y].(\nu z\Of{C}.(P \mid R) \mid Q)}
\end{array}
\]
\end{frame}

\begin{comment}
Subject reduction in CP proceeds by cut reductions of the logical operators
against their duals and \textit{commuting conversions} as well as some other
rules. Commuting conversions push a cut inside a logical operator and the
intuition is that they permit further communication to occur which was guarded
by a cut.
\end{comment}

\subsection{GV}

\begin{frame}
GV
\end{frame}

\begin{comment}
GV has built-in support for session types. consider the rule for sending a
value of type T along a channel N of type !T.S.
\end{comment}

\subsection{Translation}

\begin{frame}
something about a translation
\end{frame}

\begin{comment}
the translation to CP is
presented. blah blah something about the session types being a little odd or
overlook this probably
\end{comment}

\begin{frame}
- subject reduction of CP
- top-level cut elimination
- translation preserving well-typedness
\end{frame}

\subsection{Issues}

\begin{comment}
the system has three main properties. subject reduction of CP, top-level
cut-elimination and translation preserving well-typedness. of which subject
reduction is the only one fully formalised. the other two presented some
challenges but some comments on progress towards the other two is
offered. i also highlight some issues and guidelines
\end{comment}

\begin{frame}
subject reduction
\end{frame}

\begin{comment}
subject reduction is formalised using a relation on processes
\end{comment}

\begin{frame}
problems for cut elimination
\end{frame}

\begin{comment}
sessions correspond to propositions
processes correspond to proofs
cut elimination corresponds to communication

cut elimination is not currently proven since we require a termination measure
on the length of a derivation and a relationship between the subprocesses of a
cut. other work based on formalising logics where the derivations are explicit
may be inspirational
\end{comment}

\begin{frame}
problems of the translation
\end{frame}

\begin{comment}
the translation seems to require a duplication of the specifications for cp
and gv typing rules not done

what can we show them for the failures?

here are some issues and things learnt! -- our guidelines are all about
modularisation, representation, library reuse, automation!
\end{comment}

\section{Future Work}

\begin{frame}
\begin{itemize}
\item Propositions as Sessions
\item system features
\item Coq
\item encoding
\item subject reduction theorem
\item difficulties in formalisation
\item implications
\item future work
\end{itemize}
\end{frame}

\printbibliography

\end{document}
