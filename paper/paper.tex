\documentclass{mpaper}

\usepackage{macros}
\usepackage{comment}
\usepackage{listings}
\usepackage{lstcoq}
\usepackage{graphicx}
\usepackage{xspace}
\usepackage{cmll}
\usepackage{prooftree}
\usepackage{amsmath}
\newcommand{\typestate}[2]{{#1}\gg{#2}}
\usepackage[style=alphabetic,sorting=nymt,natbib=true,
  maxbibnames=100]{biblatex}
\addbibresource{paper.bib}

\DeclareSortingScheme{nymt}{
  \sort{
    \field{author}
    \field{year}
    \field{month}
    \field{title}
  }
}

\input{propmacros}

\newcommand{\fpop}{System F${}^\circ$\xspace}

\begin{document}

\title{Propositions as Sessions, Mechanically}
\author{Craig McLaughlin}
\matricnum{1002524}

\maketitle

\begin{abstract}
\begin{comment}
SPL (+CPL)

WTD

ROF

IMP
\end{comment}
\end{abstract}

\section{Introduction}\label{sec:intro}

Distributed communication systems are becoming increasingly prevalent in
modern society. To facilitate communication between concurrently executing
agents requires complex network protocols to define the type and sequencing of
messages. Typically these protocols are implemented in systems programming
languages, such as C, which provide no correctness guarantees of the
implementation. Furthermore, programming in these languages is often extremely
error-prone, as one has a myriad of unsafe features at one's disposal. As more
businesses begin to conduct transactions over the Web, it is imperative that
they can reason about the communication protocols upon which they rely.

Encoding communication protocols as \textit{session types} is one approach to
achieve guarantees about correctness. One particular variant of session types
are \textit{binary} session types~\footnote{There are also \textit{multiparty}
 session types, but I do not discuss them here.}. A binary session type
specifies communication between two agents, and it specifies the order and
type of messages to be sent or received by an agent in the system. The two
agents have dual session types such that, for example, when one is expecting
to receive a message the other is expecting to send a message; both session
types agree on the type of message to be exchanged. In this way, correctness
of communication can be statically assured by providing communicating agents
with a \textit{channel} whose endpoints have dual session types. A channel is
defined as a bi-directional conduit for exchanging messages, not unlike a
socket in network programming. In contrast to sockets, however, a channel is
associated with an explicit type which provides a description of its
protocol. Thus, in session-based systems a channel is usually provided as a
primitive type.

In programming language research, work on static type systems is usually
presented on paper complete with informal proofs of correctness for the system
properties. Most types systems in the session types community have been
developed in this way. However, it is more difficult to extend work using this
approach, as it may be unclear how changes affect proofs and one will
typically have to re-consider all proofs to be convinced the properties still
hold. More generally, unassisted formalisms are error-prone to develop and do
not provide a firm basis upon which other researchers can experiment.

Proof assistants such as Coq~\cite{Coq:manual} offer a platform on which to
develop programming languages and type systems and associated proofs of
properties with strong guarantees of correctness. Not only is proving with a
proof assistant much less error-prone than the unaided approach, it also eases
extension of the system since the proof assistant will highlight parts of
proofs that have been affected by changes. On the other hand, one may have to
prove more properties using this approach since this setting does not permit
appealing to human intuition. For example, alpha-equivalence and freshness of
binders are usually assumed in informal presentations, whereas in the
mechanised setting one has to explicitly encode and reason about these
properties~\cite{Aydemir:2005:MMM, Aydemir:2008:EFM}.

This project describes work towards the development of a framework for
formalising lambda calculus type systems with session types using interactive
theorem proving (in particular, the system Coq). The framework should enable a
whole class of related languages and type systems to be formalised with little
extra proof effort. Inspired by previous work on a mechanised framework for
$\pi$-calculus type systems~\cite{Gay:2001:FFP}, the current work focuses on
the lambda calculus to provide a basis on which session types for mainstream
programming languages can be studied, whilst taking advantage of previous
proof effort and specialising only for those parts unique to the particular
system. The starting point for the framework is the calculi developed by
\citeauthor{Wadler:2014}~\cite{Wadler:2014} describing a relationship between
classical linear logic (CP) and a functional language with session types (GV).

\section{Related Work}\label{sec:rw}

The background for this project can be categorised roughly as previous work on
session-based type systems (sub-divided into $\pi$ and $\lambda$-calculi
variants, \S \ref{sec:pis} and \S \ref{sec:lam}, respectively) and previous
work on formal verification using proof assistants (particularly focussed on
programming language mechanisation). Finally, some recent work has merged
these two disciplines by verifying a session-based $\pi$-calculus system (\S
\ref{sec:asts}).

\subsection{Session-based Type Systems and Linear Logic}\label{sec:sts}

\subsubsection{Preamble}\label{sec:pre}

The definition of session types will be important for the remainder:
\input{../paper/session-types.tex}

Here, I use a modified version of the definition given by
\citeauthor{Gay:2010:LAST}~\cite{Gay:2010:LAST} where I have omitted recursive
session types. The type \lstinline{end} denotes the terminal session type and
a channel typed as such may not perform any communication. A communication
channel with session type $\inpt{T}{S}$ expects to receive a term of type $T$
and then continues with session type $S$. Conversely, a channel with type
$\outpt{T}{S}$ can send a term of type $T$ and then has type $S$. Thus, input
and output are considered \emph{dual} session types, in the sense that a
channel with one endpoint having type $\inpt{T}{S}$ and the other endpoint
having type $\outpt{T}{\Sbar{S}}$, where $\Sbar{S}$ is the dual of $S$,
permits communication between two agents, allowing one to send a term of type
$T$ and the other to receive it with continuing endpoint types $\Sbar{S}$ and
$S$, respectively. Similarly, the remaining types $\Branch{l_i}{S_i}{i\in I}$
and $\Choice{l_i}{S_i}{i\in I}$ are duals of each other. A channel of type
$\Branch{l_i}{S_i}{i\in I}$ can receive a label $l_i$ which will select the
corresponding session type $S_i$ as the continuing type of the channel. While
a channel with type $\Choice{l_i}{S_i}{i\in I}$ can send a label $l_i$ and
continues as $S_i$.

\subsubsection{In the \texorpdfstring{$\pi$}{pi}-calculus}\label{sec:pis}

\citeauthor{Caires:2010:STI} \cite{Caires:2010:STI} present a connection
between a $\pi$-calculus type system with session types ($\pi$DILL) and dual
intuitionistic linear logic (DILL)~\cite{Barber:1996}. They equate linear
propositions with session types of the process calculus via a bidirectional
translation relation. They use a binary reduction relation and a labelled
transition system to represent process reduction and process action with its
environment as is standard~\cite{Sangiorgi:2001}.

\input{../paper/sill-branch-choice-rules}

They represent dual intuitionistic linear logic as a sequent calculus
providing logical connectives which have session-based interpretations in
$\pi$DILL. Consider their rules for branch and choice in $\pi$DILL in
Figure~\ref{fig:sill-branching}, which have only two alternatives
(cf. multiple alternatives in the standard definition in \S~\ref{sec:pre}).

Note that branch and choice both have some notion of branching (R rules for
$\oplus$/L rules for $\with$) and at least for \& this is counter-intuitive in
a session-based setting, since the intuition for \& is that of
\emph{offering} (receiving) a choice between alternatives rather than
\emph{making} (sending) the choice. Here, however, the intuition should be
extended to account for its location in the typing judgement. The channel is
on the left of the sequent, and \citeauthor{Caires:2010:STI} suggest one
consider the context as services being provided to the typed process. Thus,
the type of channels in the context is really the type of the other endpoint
of the channel, and the typed process behaves according to the dual
protocol. For example, considering $\SILLbranchLTwo$, and taking $A^\bot$ to
represent the dual of a protocol $A$ as defined by
\citeauthor{Wadler:2014}~\cite{Wadler:2014}, the typed process is behaving
according to the protocol $\BChoice{A^\bot}{B^\bot}$, selecting from
alternatives (in this case, $\inrterm$) and then behaving according to the
selected protocol (in this case, protocol $B^\bot$).

As noted by Wadler~\cite{Wadler:2014} there is a certain amount of redundancy
in the two-sided nature of the rules forcing one to commit to a certain
convention when typing a communication system. Consider, an equivalent system
to the buy/quote example given by
\citeauthor{Caires:2010:STI}~\cite[\S~3]{Caires:2010:STI}:
\begin{gather*}
\sdef{ClientProto}{\BChoice{(\tensor{Book}
                            {(\tensor{Card}{(\lfn{Receipt}{\1})})})}
                           {(\tensor{Book}{(\lfn{Quote}{\1})})}}
\end{gather*}

Note, I am using $\tensor{}{}$ for session output and $\lfn{}{}$ for session
input following the presentation by \citeauthor{Caires:2010:STI}. In the
protocol defined above, a client selects between buying a book or receiving a
price quote for a book. In the buy option case, the client sends the name of
the book to the server and their card details, then the server sends the
receipt for the purchase. In the quote option case, the client sends the name
of the book and receives a price quote from the server. I have replaced the
types $N$ and $I$ used by \citeauthor{Caires:2010:STI} with more meaningful
type names $Book$, $Card$, $Quote$ and $Receipt$ where appropriate; all are
synonyms for the type $\1$ which denotes the terminal session type in this
system. The client and server process bodies are as follows:
\begin{gather*}
\sdef{ClientBody_c}
     {\CPinr{c}{\SLoutput{1984}{c}{\SLinput{c}{quote}{\0}}}}\\
\sdef{ServerBody_c}
     {\CPcase{c}
             {\SLinput{c}{book}{\SLinput{c}{card}{\SLoutput{receipt}{c}{\0}}}}
             {\SLinput{c}{book}{\SLoutput{quote}{c}{\0}}}}
\end{gather*}

\begin{samepage}
The typings for the client and server processes are given by:
\begin{gather*}
\tsequent{\cdot}{\cdot}{ClientBody_c}{\typedid{c}{ClientProto}}
\tag{\mkTrule{ClientBody}} \label{eq:cbtyp}
\\ \tsequent{\cdot}{\typedid{c}{ClientProto}}{ServerBody_c}{\typedid{-}{\1}}
\tag{\mkTrule{ServerBody}} \label{eq:sbtyp}
\end{gather*}
\end{samepage}

The derivation for \eqref{eq:cbtyp} is $T\1 R$, $\lfn{T}{R}$, $\tensor{T}{R}$,
$\BChoice{T}{R_2}$ and \eqref{eq:sbtyp} is derivable from
$\BChoice{T}{L}$. Except for the final rule, these are exact dual rules of the
rules used in example by \citeauthor{Caires:2010:STI}. Indeed, consider the
composite process:
\begin{gather*}
\sdef{QSimple}{\Spar{c}{ClientBody_c}{ServerBody_c}}\\
\tsequent{\cdot}{\cdot}{QSimple}{\typedid{-}{\1}}
\end{gather*}

The final system is near identical to the one produced in the example given by
\citeauthor{Caires:2010:STI} except the individual processes within the
parallel composition have been swapped. Here the client communicates along the
channel $c$ on the right-side of the sequent and the server utilises the
channel $c$ on the left of the sequent. This typing, while correct, violates
the intuition given by \citeauthor{Caires:2010:STI} of the context providing
the services used by the process, since one would usually associate provision
of services with the server not the client. Instead, the example above
suggests the server utilises some channel provided by the client. On the other
hand, one could imagine such a channel being setup between two communicating
agents; the ``owner'' of the channel is largely irrelevant. Note that
$ClientProto$ is in fact the dual of the $ServerProto$ definition by
\citeauthor{Caires:2010:STI} using the definition of dual used in Wadler's
classical process calculus~\cite{Wadler:2014}. In $\pi$DILL, the duality
between endpoints of the same channel are obscured by the nature of the typing
judgements.

Process reduction steps are equated with proof reduction via cut
elimination. The relationship with proof normalisation in DILL provides
absence of deadlocks in session-based communication for the process
calculus. The correspondence of session types to linear logic propositions is
an important step in providing a solid logical foundation for a concurrent
type theory; in the same way ``sequential'' type theory ($\lambda$-calculi)
profitted from a logical perspective. However, for session types to become a
more usable tool for programming distributed communication systems (the
ultimate goal, of course, is to write more correct programs), one cannot be
expected to program directly in the $\pi$-calculus; a more mainstream
programming paradigm must be built upon these solid logical foundations. With
that in mind, enter the $\lambda$-calculus!

\subsubsection{In the \texorpdfstring{$\lambda$}{lambda}-calculus}
\label{sec:lam}

A series of works by \citeauthor{Gay:2003:STI}~\cite{Gay:2003:STI} and
\citeauthor{Vasconcelos:2006:TCM}~\cite{Vasconcelos:2006:TCM} provide a
$\lambda$-calculus based language with session types for channel
primitives. The type system is nonstandard, featuring an additional
environment for tracking the session types of channels; these types are
modified during term reduction to reflect communication. The extra channel
environment is provided to support possible aliasing of channels by treating
channel variables as pointers or references into the channel environment. So,
for a channel $c$ of session type $S$, a variable $x$ referring to this
channel would be declared to have type $Chan~c$ and $c~:~S$ would be in the
channel environment. The typing judgements and term reduction relation must be
augmented to handle these environments. Unfortunately, a side-effect of this
is that function types must specify the pre and post-states of channel
environments and therefore, the type of arguments cannot work up to
alpha-equivalence of channel identifiers. That is, if two channels $c$ and $d$
have the same session type, one cannot define a function to operate on
variables of either channel type since the function definition will explicitly
mention the identifier for the channel (in this case either, $Chan~c$ or
$Chan~d$). However, the system does provide an attractive non-linear channel
type which has been neglected in favour of a linear treatment of channels in
more recent
works~\cite{Gay:2010:LAST,Mazurak:2010:LCC,Wadler:2014}. Certainly, it is the
case that an aliased approach would fit better with mainstream programming
languages and perhaps studying a similar system could offer some insights.

The ``adoption and focus'' system~\cite{Fahndrich:2002} provides a notion of
aliased access to linear resources. The type system requires special language
features, e.g. to manage capabilities which can be thought as a form of object
liveness mechanism, so GV typing judgements would need to be extended such
that the capabilities can be included in soundness results. An extension to
the translation to CP to incorporate the ``adopt'' and ``focus'' constructs
would also need to be defined. It is not immediately clear how these features
would assist in the management of session typed channels. The ``focus'' rule
(and linearity generally) enforces an invariant on the focussed object
(channel) such that the type is maintained during the focus operation:
\input{../proposal/focus-rule}

The typing judgements include \emph{capabilities} that track aliasing to heap
objects, e.g. $\AFcap{\rho}{h}$ denotes a mapping from a static name $\rho$ to
a heap type $h$, and a variable $x$ may be typed as $\typedid{x}{\AFtr{\rho}}$
indicating that $x$ refers to an object of type $h$. The purpose of the
capabilities is to enforce restrictions on when an object can be
referenced. In other words, if $\AFcap{\rho}{h}$ is in the capabilities at
some program point then $x$ may be used, otherwise such use is prohibited. In
the [focus] rule, evaluating $e_1$ retrieves the object to be focussed. Note
the type of $e_1$ is a ``guarded'' type. The guard $G$ is the static name of
some object which ``adopted''~\footnote{I omit the adopt typing rule for
  brevity.} an object of heap type $h$. If a program point has
$\AFcap{G}{h_1}$ in the capabilities for some $h_1$ then all objects guarded
by $G$ may be used; $\capsequent{\Delta}{C_1}{G}$ denotes containment of a
such a capability in $C_1$. The guarded type may be thought of as policing
manipulation of linear components within $h$. Treating $\otimes$ as the
disjoint union for capability sets, the typing for $e_2$ temporarily removes
the guard $G$ from the set of capabilities, and adds a new variable $x$, and
associated capability, with a type permitting access to the object of type $h$
i.e. a non-guarded type. Removing $G$ will prohibit access to allow objects
guarded by $G$ for the during of $e_2$. The final capabilities after executing
$e_2$ are required to be $\tensor{C_3}{\AFcap{\rho}{h}}$, enforcing that the
type must remain as $h$. The typing of the $\letterm$ expression ensures that
the guard $G$ (contained in $C_1$) is restored.

Such a rule would appear to only benefit recursive session types. Indeed,
focussing on a non-recursive channel would be pointless since one would be
prevented from communicating across it since the focus rule requires
maintenance of the channel type. Further, it would be undesirable to permit
modification of a session type without guaranteeing exclusive access to the
channel since this could lead to invalid communication e.g. trying to
communicate on a closed channel. Additionally, a linear object is consumed
upon being adopted and will be deallocated when its adopter's lifetime ends,
although an alternative semantics could be defined which returned the linear
resource to the context. Moreover, \citeauthor{Fahndrich:2002} do not provide
operational semantics or soundness results for the ``adoption and focus'' type
system.

The Alms language~\cite{Aldrich:2009} provides a functional language with
affine types based on linear logic. A notion of type \textit{kind} is used to
distinguish between affine and unrestricted values. The typing judgements use
two contexts; one for variables with unrestricted kind and another for
variables of affine type and type variables. Functions are also labelled with
a kind which may depend on their arguments e.g. a multiple argument function
must have affine kinding if it accepts an affine typed resource as an argument
other than the final argument. The reason for this is simply to prevent the
function from using an affine resource more than once. Additionally, functions
act as closures over their environments so their qualifier may be determined
by a free variable in the environment, and a relation is provided to calculate
the appropriate kind qualifier. Type variables are provided to support kind
polymorphism of function qualifiers. The system is expressive enough to
implement session types as a module using a similar approach to
\citeauthor{Gay:2010:LAST}~\cite{Gay:2010:LAST} although treating channels as
affine rather than linearly typed. \citeauthor{Aldrich:2009} note that Alms'
type system can support the ``adoption and focus'' system but do not specify
details or whether any changes are necessary to their typing judgements.

The work on a linear functional language with session types by
\citeauthor{Gay:2010:LAST}~\cite{Gay:2010:LAST} is the main influence for the
current project from the body of work on session-based $\lambda$-calculus type
systems. They provide paper proofs of their system's type safety. Given the
non-trivial features of the type system such as recursive session types and
buffered channels for supporting asynchronous communication it will be
challenging to extend these proofs manually. A mechanised version would
provide stronger guarantees of correctness and allow others to more easily
alter proofs as a result of changes made to the language.

\subsubsection{Fusion}

A number of systems incorporate both a functional language surface syntax with
a translation to a more primitive process calculus. I shall focus on two such
systems presented recently which have a connection to linear logic.

Lolliproc~\cite{Mazurak:2010:LCC} provides a functional language with
concurrency primitives as a surface syntax on top of an underlying process
calculus. The process calculus provides a classical linear logic
interpretation for the functional language, utilising double negation
elimination to provide session type duality. The surface syntax is an
effective abstraction layer for the programmer since it does not expose the
underlying process calculus.

Concurrency is provided by control operators which, respectively, spawn a
child process and wait for a child process to complete. The spawning process
creates a channel between parent and child process; a channel is represented
as a continuation and the type denotes the communication protocol
(i.e. session type) between parent and child.

\citeauthor{Mazurak:2010:LCC} present proofs for type safety, strong
normalisation and confluence. Confluence provides the guarantee that no race
conditions can occur, strong normalisation prohibits non-terminating programs
and type safety assures deadlock-freedom. Deadlock-freedom is implied by the
acyclic communication graphs (progress of process reduction) which occur
between parallel processes; follows from permitting only one channel between
two halves of parallel composition construct in the process calculus. Most of
the development is supported by Coq proof scripts with remaining issues due to
reasoning about communication graphs. The development does not provide
primitive send and receives; instead, these are encoded as linear functions.
%% and classical extension to second-order logic by
%% \citeauthor{Mazurak:2013:LPP}'s PhD thesis~\cite{Mazurak:2013:LPP}.

\citeauthor{Wadler:2014}'s recent work~\cite{Wadler:2014} brings together a
process calculus, CP, based on the earlier work by
\citeauthor{Caires:2010:STI} with a functional language, GV, based on LAST by
\citeauthor{Gay:2010:LAST}. GV presents session types using the standard
presentation as described in \S~\ref{sec:pre}. CP presents linear logical
connectives with session type interpretations inspired by
\citeauthor{Caires:2010:STI}~\cite{Caires:2010:STI}. \citeauthor{Wadler:2014}
describes a continuation-passing style (CPS) translation from GV session types
to CP classical linear logic propositions. The process calculus CP is slightly
different to $\pi$DILL by \citeauthor{Caires:2010:STI}, apart from being
classical in nature, the constructs for server replication are modified; CP
provides a weakening and contraction rules whereas these are encoded in one
rule for process reduction by \citeauthor{Caires:2010:STI}. Additionally,
rather than a two-sided sequent calculus, \citeauthor{Wadler:2014} uses
one-sided sequents for defining the process calculus, which provides a more
intuitive presentation of session type duality and clearer correspondence to a
$\lambda$-calculi surface syntax, simplifying the translation presentation. As
presented, GV does not support all features of CP and thus the translation is
one way (GV to CP). \citeauthor{Lindley:2014:SAP}~\cite{Lindley:2014:SAP}
extend GV to provide support for polymorphism and replication, following a
similar CPS translation scheme. Lastly,
\citeauthor{Lindley:2014:SPS}~\cite{Lindley:2014:SPS} describe operational
semantics for GV and their system has greater similarities with LAST than
prior GV works, for example, by treating send and receive as linear functions
rather than language primitives.

\subsection{Mechanising Programming Language Metatheory}

Interactive theorem proving and proof assistants have seen an upsurge in use
in recent years. Especially within the domain of programming language
research, there is a strong emphasis on providing mechanised proofs
accompanying work in the area. Indeed, \citeauthor{Aydemir:2005:MMM} have
published a series of challenges on mechanising programming languages aimed at
providing a starting point for comparing different representation
techniques~\cite{Aydemir:2005:MMM}. Another aim is to provide reusable
libraries for common reasoning needed across programming language
developments, e.g. handling of typing environments. This effort has resulted
in a number of different approaches for representing programming languages
within proof assistants. For instance,
\citeauthor{Aydemir:2008:EFM}~\cite{Aydemir:2008:EFM} present a representation
of $\lambda$-calculi where bound variables are represented as \textit{de
  Bruijn indices}~\footnote{A de Bruijn index is a number used to represent a
  bound variable which indicates the position of its binder (starting from
  zero for the innermost binder). For example, $\lambda~(\lambda~1)$
  corresponds to $\lambda x. \lambda y. x$, i.e. the constant function.} and
free variables are represented as named terms; the \textit{locally nameless}
representation. Their work resulted in a library for handling commonly
occurring aspects in programming language metatheory which has been used since
in other developments~\cite{Park:2014:MMW}. Reusable libraries reduce the
proof engineering effort needed for later works, in contrast to the
pen-and-paper approach, and some proof assistants (as is the case with Coq)
allow one to extract a program from the development which can provide a
typechecker or compiler for the language formalised.~\footnote{Curry-Howard
  strikes again; a proof of decidability of typechecking corresponds to a
  program implementing a typechecker for the language.}

Some recent mechanisation effort focuses on providing a basis for studying
linearity within type systems. This work is of interest to the current project
since most session-based type systems assume a strictly linear type system
which requires re-binding of channel identifiers, such as in the functional
setting of \citeauthor{Gay:2010:LAST}. \citeauthor{Mazurak:2010:LLT} present
an extension to System F (termed \fpop) with a notion describing types as
having linear or non-linear \textit{kind}~\cite{Mazurak:2010:LLT}. This
extension is motivated by previous work on incorporating linearity into type
systems. Overall, previous attempts either hamper the inclusion of desirable
programming features (such as polymorphism), or do not adequately reflect
non-linearity as the common case leading to awkward programming. \fpop avoids
these deficiencies by categorising types into kinds whilst maintaining similar
semantics to System F. Mechanised proofs for type soundness and parametricity
are presented, and the semantics allow non-linear types to be treated as
linear. Examples show the system can provide a wide range of permissions on
interfaces, from full exclusive access to read-only shared references. The
system is very close to the Alms language described by
\citeauthor{Aldrich:2009} but has the advantage that the soundness results
(type safety and parametricity) have been entirely mechanised in Coq. It would
be interesting to see if one could encode the ``adopt'' and ``focus''
constructs in this system to compare its expressiveness to Alms. The ``adopt''
rule can be encoded similarly to the ShareRef
example~\cite{Mazurak:2010:LLT}. It is not immediately clear how to encode the
``focus'' rule within the present semantics, as one needs to prevent
non-linear access to its argument implying the presence of knowledge about
aliasing within the typing judgements; absence of aliasing is not identified
with linear kinded types in \fpop.

While not related to programming language metatheory,
\citeauthor{Gay:2001:FFP}~\cite{Gay:2001:FFP} provides a $\pi$-calculus
framework mechanised in Isabelle/HOL. The aim is to build a mechanisaton of
session-based type systems on top of the $\pi$-calculus framework. The use of
de Bruijn indices for both bound and free variables causes issues with
variable substitution often requiring permutation of typing environments (see
\citeauthor{Aydemir:2008:EFM}~\cite{Aydemir:2008:EFM} for a discussion on
binder representations) and lifting of free variables during substitution; I
avoid this issue in my representation choice (\S \ref{sec:approach}).

The introduction of names for hypotheses during execution of custom tactics
are an issue in the proof development. These names are automatically generated
by the Isabelle/HOL system which creates a dependency between the names chosen
and the tactic. Thus, one must be careful to use the exact names expected by
the tactic. In the Coq proof assistant, defining custom tactics can be
achieved using the Ltac language~\cite{Delahaye:2000:TLS}. Among other things,
Ltac supports pattern matching on hypotheses and goal forms. Thus, if one
wished to pattern match on an inductive type describing variables, one could
do so without mentioning the actual variable name as follows:

\begin{coq}
Ltac my_tactic :=
  match goal with
  | [v: var |- _] =>
    ... tactics here possibly mentioning `v' hypothesis ...
  end.
\end{coq}

\subsubsection{Applications to Session-based Type Systems}\label{sec:asts}

\citeauthor{Goto:2014}~\cite{Goto:2014} provide a $\pi$-calculus session-based
type system providing session polymorphism. The system is more general than
session polymorphism via subtyping~\cite{Gay:2005:SST} in that it is capable
of typing a generic forwarding process between mutually dual session
types. Defining such a process is not possible using subtyping since one
wishes to restrict the types to be dual, not a subtype of some other
type. This more general form of polymorphism is achieved by permitting input
on all session types (including \lstinline{end}, the terminal session type)
and then employing transition hypotheses to ensure the type permits such
input. The authors mechanise their type system and its properties in the Coq
proof assistant. However, the mechanised system is restricted to the
$\pi$-calculus and the main focus is proving soundness properties for the
deduction rules allowing polymorphism, rather than a more general basis for
studying programming with session types.

\section{Formalisation}

The formalisation was performed using the Coq proof
assisstant~\cite{Coq:manual}. In the spirit of the POPLMARK
challenge~\cite{Aydemir:2005:MMM}, the development utilises available
libraries and infrastructure as much as possible. In particular,
\citeauthor{Aydemir:2008:EFM}~\cite{Aydemir:2008:EFM} developed a metatheory
library for handling, among other things, association lists (environments) and
free variable representation. The current development uses the version of the
library distributed by~\citeauthor{Park:2014:MMW}~\cite{Park:2014:MMW} which
has been updated for Coq version 8.4pl4. One goal of the formalisation effort
was to minimise the extent to which the development differs from the
pen-and-paper presentation and avoid questions of adequacy of the
representation. Some changes were made to ease the mechanisation and are
highlighted where they occur.

\subsection{Preliminaries}\label{sec:approach}

The locally nameless first-order representation for binders and free variables
was adopted for both GV and CP, following
\citeauthor{Aydemir:2008:EFM}~\cite{Aydemir:2008:EFM}. This first-order
variant prevents variable-capture issues when compared with other first-order
approaches. Alternatively, I could have chosen a higher-order abstract syntax
(HOAS) approach such as the parametric version (PHOAS) described
by~\citeauthor{Chlipala:2008:PHOAS}~\cite{Chlipala:2008:PHOAS}. PHOAS relies
on the metalanguage (Coq, in this case) for handling binders and substitution
so has less overhead in managing syntax than the locally nameless
approach. However, it was less clear how to handle linearity using this
approach and has the disadvantage of being able to represent terms not valid
in the language being mechanised (so called ``exotic'' terms). Further, a
higher-order approach would prevent the use of the Metatheory library which
provides a number of useful tactics for manipulating typing contexts.

Previous efforts to mechanise \fpop~\cite{Park:2014:MMW} illustrate how to
handle a language containing both linear and non-linear contexts. However, to
stay true to CP/GV, I maintained a single context. Interestingly, it became
clear that the mechanised version of CP required explicit weakening and
contraction to facilitate the reduction rules (\S~\ref{sec:cp}).

\input{with-connect-rule}

For handling binder freshness, I chose to adopt the cofinite quantification
approach described by~\citeauthor{Aydemir:2008:EFM}, which excludes a finite
set of variables from being considered as the binder. In contrast, the
traditional ``exists-fresh'' approach, where the binder is only required to be
fresh within the abstraction's body, does not produce strong enough induction
principles in some cases. This change will necessitate changes to the typing
rules of GV and CP. Consider for instance the Connect rule in GV (C) and its
corresponding cofinite quantification version (CCO) in
Figure~\ref{fig:connect}. The conclusion specifies a variable in (C) but a
type in (CCO) (de Bruijn index rather than a name). Thus, in the premise for
(CCO) one can choose a suitably fresh $x$ in each premise. Note that, $L$ can
be chosen such that $\Psi \cup \Phi \cup \fv(M) \cup \fv(N) \subseteq L$,
where $\fv(M)$ are the set of free variables in term $M$, and $x$ can be the
same in both premises. Similar changes are made to the rules for CP. These
changes do not alter the typing of processes nor the semantics of the
translation from GV to CP. An equivalence between ``exists-fresh'' and
cofinite quantification definitions of the simply-typed $\lambda$-calculus is
given by \citeauthor{Aydemir:2008:EFM}~\cite{Aydemir:2008:EFM}, and I suspect
a similar result could be derived straightforwardly (but tediously) for the
CP/GV system.

Another aspect of the encoding is how to define terms. The intrinsic encoding
described by~\citeauthor{Benton:2012:STT}~\cite{Benton:2012:STT} is one
approach, indexing terms by their type so as to prevent ill-formed terms from
being constructed. However, in the encoding for CP/GV there are issues with
using this encoding: $(1)$ it is not immediately clear how to handle linear
contexts using the de Bruijn variable encoding, since in the intrinsic setting
the environment automatically supports weakening; $(2)$ an intrinsic encoding
of GV terms would be complicated by the need to enforce that session types
occur in certain instances (by use of a predicate); and $(3)$ well-typed terms
require extra assumptions about binder freshness which cannot reasonably be
expressed as a function type. For these reasons, an intrinsic approach does
not offer much benefit since a well-typed term relation would still need to be
defined. Therefore, I chose an extrinsic encoding for terms and define
well-typed terms as a separate inductive type.

\citeauthor{Aydemir:2008:EFM}~\cite{Aydemir:2008:EFM} note that the size of
their language proof infrastructure is proportional to the number of binding
constructs. In the case of a simply typed lambda calculus this is not onerous,
but GV has four binding constructs, CP has six and propositions have
two. Indeed, a lot of effort was expended setting up this
infrastructure. However, I believe one of the contributions of this work is to
articulate what one needs from state of the art metatheory libraries in order
to handle session-based languages, and more generally, linear type systems.

\citeauthor{Park:2014:MMW} describe a technique for
removing nonlinear contexts from typing judgements. While their work extended
to \fpop it is not clear how to handle an environment containing both
non-linear and linear types as in GV. I wish to maintain as close a
relationship as possible to the paper system presented by
\citeauthor{Wadler:2014}, so separating out the non-linear and linear
components (as in \fpop) is not an option at this stage.

\begin{comment}
\section{Issues}

\begin{itemize}
\item What is required of a Metatheory library for linear type systems?
  Permutation reasoning? Weakening/Contraction for non-linear components?
\item Discuss the different approaches that were taken to maintain close
  correspondence with the paper presentation
\item Make sure to note that the paper leaves details (a lot of the ``cruft'')
  out of the proofs e.g. where weakening is applied in the typing derivations
\item Mention the use of Metatheory and its limitations when mechanising
  linear type systems like GV/CP
\end{itemize}
\end{comment}

\subsection{The process calculus CP}\label{sec:cp}

\begin{comment}
FIGURES

propositions

processes

typing judgements

equivalences and axiomatic cut

principal cut rules

commuting conversions
\end{comment}

Formalising the process calculus CP provided many challenges for the
metatheory library since to my knowledge, the library has never been applied
to a process calculus before. So for instance, in the lambda calculus one
typically does not work up to permutation of binders, whereas in a process
calculus these kinds of structural equivalences are standard. Additionally,
substitution and opening are only defined on processes for names. In other
words, one cannot substitute an arbitrary process term for a name, unlike in
the lambda calculus. Thus frameworks which assume a lambda calculi style
substitution operation are not immediately amenable to the CP
setting~\cite{Lee:2012}.

Note that the rules for polymorphism, $\exists$ and $\forall$, are defined but
cut elimination on them is not. Since GV (\S~\ref{sec:gv}) does not support
polymorphism the reduction rules are unnecessary for the translation. Future
work is to support reduction under these terms.

Initially, an implicit notion of weakening and contraction were chosen so as
to be in line with \citeauthor{Wadler:2014}'s definitions. However, explicit
weakening and contraction were required to differentiate the reduction rules
for the various interactions between servers and clients.

Ordering in environments is ignored and the development required lemmas
allowing the permutation of environments. Support for permutating environments
is not currently supported in the Metatheory library but some general lemmas
were added as a result of this work. Additionally, custom tactics were
developed to automatatically solve some simple permutation goals. However,
these tactics are not a ``catch all'' and some generalising still needs to be
done.

The paper presentation omits details: the principal cut rules do not specify
weakening could occur: since weakening is implicit is tacitly assumed
weakening can always be pushed further up the derivation tree e.g. AxCut rule

another interesting aspect which the formalism reveal is the rule for
associativity is constructed in a way to permit associativity in a certain way
pre-determined

metatheory library and the library of tactics from software foundations are
used extensively: metatheory does not handle multiple binders (check this?)
maybe add a generic tactic to handle multiple binders... or perhaps add a
lemmas for handling binders

\subsection{The functional language GV}\label{sec:gv}

\begin{comment}
FIGURES

types

terms

typing judgements
\end{comment}

While the aim is to be faithful to \citeauthor{Wadler:2014}'s description, I
may need to alter the approach slightly to avoid tricky formulations. For
instance, instead of providing $n$-ary branch and choice in GV, I provide
only binary versions of these operators to simplify the development. This
change is not restrictive however, since CP itself provides only binary
versions of plus ($\oplus$) and with ($\with$) constructs. Likewise, on a more
technical note, I amalgamate all types into one inductive definition and
provide a predicate for restricting typing rules to consider only valid
session types. \citeauthor{Wadler:2014} defines GV types as a set of mutually
recursive definitions; session types are types which may contain types as
subcomponents (arguments to send, for example). Unfortunately, handling
mutually inductive definitions in Coq can be quite involved; requiring one to
either rely on the Coq system to provide a stronger mutual induction principle
or defining one manually. Such a definition is possible, but it complicates
elimination via the induction principle.

\subsection{CPS translation GV to CP}

Currently the formalisation does not handle this. Future work.

\section{Future Work}

In addition to that already mentioned: there remains much to be done.

\section{Conclusions}


{\bf Acknowledgments.}
This is optional; it is a location for you to thank people

\sloppy
\printbibliography

\end{document}
