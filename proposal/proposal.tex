\documentclass{mprop}

% Include Coq lstlisting language definition and things upon which it depends.
\usepackage{macros}

\usepackage{hyperref}
\usepackage{listings}
\usepackage{lstcoq}
\usepackage{graphicx}
\usepackage{xspace}
\usepackage{cmll}
\usepackage[style=alphabetic,natbib=true,maxbibnames=100]{biblatex}
\addbibresource{proposal.bib}

% alternative font if you prefer
%\usepackage{times}

% for alternative page numbering use the following package
% and see documentation for commands
%\usepackage{fancyheadings}

\newcommand{\fpop}{System F${}^\circ$\xspace}

% other potentially useful packages
%\uspackage{amssymb,amsmath}
%\usepackage{url}
%\usepackage{fancyvrb}
%\usepackage[final]{pdfpages}

\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{Mechanisation of Session-based Lambda Calculus Type Systems}
\author{Craig McLaughlin}
\date{\today}
\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\tableofcontents
\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}\label{intro}

Two aspects of programming language research are relevant for this project. The first is concerned with static type systems for ensuring runtime safety properties for concurrent communication systems. The second is the increasing use of proof assistants and interactive theorem provers for studying and mechanically verifying the semantics and properties of programming languages.

\subsection{On Communication}

Distributed communication systems are becoming increasingly prevalent in modern society. To facilitate communication between concurrently executing agents requires complex network protocols to define the type and sequencing of messages. Typically these protocols are implemented in systems programming languages, such as C, which provide no correctness guarantees of the implementation. Furthermore, programming in these languages is often extremely error-prone, as one has a myriad of unsafe features at one's disposal. As more businesses begin to conduct transactions over the Web, it is imperative that they can reason about the communication protocols upon which they rely.

Encoding communication protocols as \textit{session types} is one approach to achieve guarantees about correctness. One particular variant of session types are \textit{binary} session types~\footnote{There are also \textit{multiparty} session types, but I do not discuss them here.}. A binary session type specifies communication between two agents, and it specifies the order and type of messages to be sent or received by an agent in the system. The two agents have dual session types such that, for example, when one is expecting to receive a message the other is expecting to send a message; both session types agree on the type of message to be exchanged. In this way, correctness of communication can be statically assured by providing communicating agents with a \textit{channel} whose endpoints have dual session types. A channel is defined as a bi-directional conduit for exchanging messages, not unlike a socket in network programming. In contrast to sockets, however, a channel is associated with an explicit type which provides a description of its protocol. Thus, in session-based systems a channel is usually provided as a primitive type.

\subsection{On Verification}

In programming language research, work on static type systems is usually presented on paper complete with informal proofs of correctness for the system properties. Most types systems in the session types community have been developed in this way. However, it is more difficult to extend work using this approach, as it may be unclear how changes affect proofs and one will typically have to re-consider all proofs to be convinced the properties still hold. More generally, unassisted formalisms are error-prone to develop and do not provide a firm basis upon which other researchers can experiment; often it will require ``rolling your own'' compiler for the language of interest.

Proof assistants such as Coq~\cite{Coq:manual} offer a platform on which to develop programming languages and type systems and associated proofs of properties with strong guarantees of correctness. Not only is proving with a proof assistant much less error-prone than the unaided approach, it also eases extension of the system since the proof assistant will highlight parts of proofs that have been affected by changes. However, one may have to prove more properties using this approach since this setting does not permit appealing to human intuition. For example, alpha-equivalence and freshness of binders are usually assumed in informal presentations, whereas in the mechanised setting one has to explicitly encode and reason about these properties~\cite{Aydemir:2005:MMM, Aydemir:2008:EFM}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Statement of Problem}

The aim of this project is to develop a framework for formalising lambda
calculus type systems involving session types using interactive theorem
proving (in particular, the system Coq). The motivation for the framework is
that it will enable a whole class of related languages and type systems to be
formalised with little extra proof effort. Inspired by previous work on a
mechanised framework for $\pi$-calculus type systems~\cite{Gay:2001:FFP}, we
shift to the lambda calculus to provide a basis on which session types for
mainstream programming languages can be studied, whilst taking advantage of
previous proof effort and specialising only for those parts unique to the
particular system. The framework will be heavily based on calculi developed by \citeauthor{Wadler:2012}~\cite{Wadler:2012} describing a relationship between classical linear logic (CP) and a functional language with session types (GV). GV is a minimal functional language supporting linearity so I believe such a basis will be general enough to support reasoning about a large class of functional languages with similar base properties.

From this framework, a number of directions can be explored including
session polymorphism, session subtyping, and permitting different forms of
aliasing within the type system. The recent work by \citeauthor{Lindley:2014:SAP} \cite{Lindley:2014:SAP}, who extend GV to HGV supporting session forwarding, replication and polymorphism, would be a interesting place to start when looking to add these extensions.

Additionally, the majority of previous session type systems for mainstream programming languages have focussed exclusively on linear type systems. One disadvantage of a linear type system is the need to re-bind objects after each operation~\cite{Gay:2010:LAST}. We could look to extend the GV type system to provide the benefits of aliasing with the guarantees of linearity, termed ``adoption and focus'' as introduced by~\citeauthor{Fahndrich:2002} \cite{Fahndrich:2002}. The ``adoption and focus'' type system is non-trivial requiring special language features, e.g. to manage capabilities which can be thought as a form of object liveness mechanism, so the GV typing judgements must be extended such that the capabilities can be included in soundness results. A translation to CP must also be defined for the ``adopt'' and ``focus'' constructs.

These extensions will argue that the framework supports a wide range of languages and type systems, providing researchers the ability to harness the power of formal verification in the design, implementation and documentation of session-based type systems.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Background Survey}

%% present an overview of relevant previous work including articles, books, and
%% existing software products. Critically evaluate the strengths and weaknesses
%% of the previous work.

The background for this project can be categorised roughly as previous work on session-based type systems (sub-divided into $\pi$ and $\lambda$-calculi variants, \S \ref{sec:pis} and \S \ref{sec:lam}, respectively) and previous work on formal verification using proof assistants (particularly focussed on programming language mechanisation). Finally, some recent work has merged these two disciplines by verifying a session-based $\pi$-calculus system (\S \ref{sec:asts}).

\subsection{Session-based Type Systems and Linear Logic}\label{sec:sts}

\subsubsection{In the $\pi$-calculus}\label{sec:pis}

\citeauthor{Caires:2010:STI} \cite{Caires:2010:STI} present a connection between $\pi$-calculus type system with session types and intuitionistic linear logic. They equate linear propositions with session types of the process calculus via a bidirectional translation relation. They use a labelled transition system to represent process reduction with observable actions on channels. They represent dual intuitionistic linear logic as a sequent calculus providing logical connectives which have session-based interpretations. Process reduction steps are equated with proof reduction via cut elimination. The relationship with intuitionistic linear logic provides absence of deadlocks in session-based communication for the process calculus. The correspondence of session types to linear logic propositions is an important step in providing a solid logical foundation for a concurrent type theory; in the same way ``sequential'' type theory ($\lambda$-calculi) profitted from a logical perspective. However, for session types to become a more usable tool for programming distributed communication systems (the ultimate goal, of course, is to write more correct programs), we cannot be expected to program directly in the $\pi$-calculus; a more mainstream programming paradigm must be built upon these solid logical foundations. With that in mind, enter the $\lambda$-calculus!

\subsubsection{In the $\lambda$-calculus}\label{sec:lam}

\citeauthor{Gay:2008:STI}~\cite{Gay:2008:STI} provide a $\lambda$-calculus based language with session types for channel primitives. The type system is nonstandard, featuring an additional environment for tracking the session types of channels; these types are modified during term reduction to reflect communication. The extra channel environment is provided to support possible aliasing of channels by treating channel variables as pointers or references into the channel environment. So, for a channel $c$ of session type $S$, a variable $x$ referring to this channel would be declared to have type $Chan~c$ and $c~:~S$ would be in the channel enviornment. The typing judgements and term reduction relation must be augmented to handle these environments. Unfortunately, a side-effect of this is that function types must specify the pre and post-states of channel environments and therefore, the type of arguments cannot work up to alpha-equivalence of channel identifiers. That is, if two channels $c$ and $d$ have the same session type, one cannot define a function to operate on variables of either channel type since the function definition will explicitly mention the identifier for the channel (in this case either, $Chan~c$ or $Chan~d$). However, the system does provide an attractive non-linear channel type which has been neglected in favour of a linear treatment of channels in more recent work~\cite{Gay:2010:LAST,Mazurak:2010:LCC,Wadler:2012}. Certainly, it is the case that an aliased approach would fit better with mainstream programming languages and perhaps the ``adoption and focus'' system~\cite{Fahndrich:2002} could offer some insights.

The work on a linear functional language with session types by \citeauthor{Gay:2010:LAST}~\cite{Gay:2010:LAST} is the main influence for the current project from the body of work on session-based $\lambda$-calculus type systems. They provide paper proofs of their systems type safety. Given the systems non-trivial features such as recursive session types and buffered channels for supporting asynchronous communication it will more difficult to extend these proofs manually. A mechanised version would provide stronger guarantees of correctness and allow others to more easily alter proofs as a result of changes made to the language.

\subsubsection{Fusion}

A number of systems incorporate both a functional language surface syntax with a translation to a more primitive process calculus. We shall focus on two such systems presented recently which have a connection to linear logic.

Lolliproc~\cite{Mazurak:2010:LCC} provides a functional language with concurrency primitives as a surface syntax on top of an underlying process calculus. The process calculus provides classical linear logical interpretation for the functional language, utilising double negation elimination to provide session type duality. The surface syntax is an effective abstraction layer for the programmer since it does not expose the underlying process calculus.

Concurrency is provided by control operators which, respectively, spawn a child process and wait for a child process to complete. The spawning process creates a channel between parent and child process; a channel is represented as a continuation and the type denotes the communication protocol (i.e. session type) between parent and child.

\citeauthor{Mazurak:2010:LCC} present proofs for type safety, strong normalisation and confluence. Confluence provides the guarantee that no race conditions can occur, strong normalisation prohibits nonterminating programs and type safety assures deadlock-freedom. Deadlock-freedom is implied by the acyclic communication graphs (progress of process reduction) which occur between parallel processes; follows from permitting only one channel between two halves of parallel composition construct in $\pi$-calculus. Most of the development is supported by Coq proof scripts with remaining issues due to reasoning about communication graphs. The development does not provide primitive send and receives; instead, these are encoded as linear functions. 
%% and classical extension to second-order logic by \citeauthor{Mazurak:2013:LPP}'s PhD thesis~\cite{Mazurak:2013:LPP}.

\citeauthor{Wadler:2012}'s recent work~\cite{Wadler:2012} brings together a process calculus, CP, based on the earlier work by \citeauthor{Caires:2010:STI} with a functional language, GV, based on LAST by \citeauthor{Gay:2010:LAST}. The work describes a continuation-passing style (CPS) translation from GV to CP treating session types as propositions in a classical linear logic. The process calculus is slightly different to that described in by $\pi$DILL~\cite{Caires:2010:STI}, apart from being classical in nature, the constructs for server replication are modified; CP provides a weakening and contraction rules whereas these are encoded in one rule for process reduction by \citeauthor{Caires:2010:STI}. Additionally, rather than a two-sided sequent calculus, \citeauthor{Wadler:2012} uses one-sided sequents for defining the process calculus. As presented, GV does not support all features of CP and thus the translation is one way (GV to CP). \citeauthor{Lindley:2014:SAP}~\cite{Lindley:2014:SAP} extend GV to provide support for polymorphism and replication, following a similar CPS translation scheme.

%% Wadler also dispenses with the structural rules; subsumed by the Assoc and Swap typing derivations and the cut reduction (double check why he does this)

\subsection{Mechanising Programming Language Metatheory}

Interactive theorem proving and proof assistants have seen an upsurge in use in recent years. Especially within the domain of programming language research, there is a strong emphasis on providing mechanised proofs accompanying work in the area. Indeed, \citeauthor{Aydemir:2005:MMM} have published a series of challenges on mechanising programming languages aimed at providing a starting point for comparing different representation techniques~\cite{Aydemir:2005:MMM}. Another aim is to provide reusable libraries for common reasoning needed across programming language developments, e.g. handling of typing environments. This effort has resulted in a number of different approaches for representing programming languages within proof assistants. For instance, \citeauthor{Aydemir:2008:EFM}~\cite{Aydemir:2008:EFM} present a representation of lambda calculi where bound variables are represented as \textit{de Bruijn indices}~\footnote{A de Bruijn index is a number used to represent a bound variable which indicates the position of its binder (starting from zero for the innermost binder). For example, $\lambda~(\lambda~1)$ corresponds to $\lambda x. \lambda y. x$, i.e. the constant function.} and free variables are represented as named terms; the \textit{locally nameless} representation. Their work resulted in a library for handling commonly occurring aspects in programming language metatheory which has been used since in other developments~\cite{Park:2014:MMW}. Reusable libraries reduce the proof engineering effort needed for later works, in contrast to the pen-and-paper approach, and some proof assistants (as is the case with Coq) allow one to extract a program from the development which can provide a typechecker or compiler for the language formalised.~\footnote{Curry-Howard strikes again; a proof of decidability of typechecking corresponds to a program implementing a typechecker for the language.}

Some recent mechanisation effort focuses on providing a basis for studying linearity within type systems. This work is of interest to the current project since most session-based type systems assume a strictly linear type system which requires re-binding of channel identifiers, such as in the functional setting of \citeauthor{Gay:2010:LAST}. As discussed previously, it would be interesting to study the system described by~\citeauthor{Fahndrich:2002}~\cite{Fahndrich:2002}, yet their system is specialised for their ``adopt'' and ``focus'' constructs and is not mechanised. \citeauthor{Mazurak:2010:LLT} present an extension to System F (termed \fpop) with a notion describing types as having linear or non-linear \textit{kind}~\cite{Mazurak:2010:LLT}. This extension is motivated by previous work on incorporating linearity into type systems. Overall, previous attempts either hamper the inclusion of desirable programming features (such as polymorphism), or do not adequately reflect non-linearity as the common case leading to awkward programming. \fpop avoids these deficiencies by categorising types into kinds whilst maintaining similar semantics to System F. Mechanised proofs for type soundness and parametricity are presented, and the semantics allow non-linear types to be treated as linear. Examples show the system can provide a wide range of permissions on interfaces, from full exclusive access to read-only shared references. It would be interesting to see if one could encode the ``adopt'' and ``focus'' constructs in this system. The ``adopt'' rule can be encoded similarly to the ShareRef example~\cite{Mazurak:2010:LLT}. It is not immediately clear how to encode the ``focus'' rule within the present semantics, as one needs to prevent non-linear access to its argument implying the presence of knowledge about aliasing within the typing judgements; absence of aliasing is not identified with linear kinded types in \fpop.

While not related to programming language metatheory, \citeauthor{Gay:2001:FFP}~\cite{Gay:2001:FFP} provides a $\pi$-calculus framework mechanised in Isabelle/HOL. The aim is to build a mechanisaton of session-based type systems on top of the $\pi$-calculus framework. The use of de Bruijn indices for both bound and free variables causes issues with variable substitution often requiring permutation of typing environments (see \citeauthor{Aydemir:2008:EFM}~\cite{Aydemir:2008:EFM} for a discussion on binder representations) and lifting of free variables during substitution; we avoid this issue in our representation choice (\S \ref{sec:approach}).

The introduction of names for hypotheses during execution of custom tactics are an issue in the proof development. These names are automatically generated by the Isabelle/HOL system which creates a dependency between the names chosen and the tactic. Thus, one must be careful to use the exact names expected by the tactic. In the Coq proof assistant, defining custom tactics can be achieved using the Ltac language~\cite{Delahaye:2000:TLS}. Among other things, Ltac supports pattern matching on hypotheses and goal forms. Thus, if we wished to pattern match on an inductive type describing variables, we could do so without mentioning the actual variable name as follows:

\begin{coq}
Ltac my_tactic :=
  match goal with
  | [v: var |- _] => ... tactics here possibly mentioning `v' hypothesis ...
  end.
\end{coq}

\subsubsection{Applications to Session-based Type Systems}\label{sec:asts}

\citeauthor{Goto:2014}~\cite{Goto:2014} provide a $\pi$-calculus session-based type system providing session polymorphism. The system is more general than session polymorphism via subtyping~\cite{Gay:2005:SST}. The authors mechanise their type system and its properties in the Coq proof assistant. However, the system mechanised is restricted to the $\pi$-calculus and the main focus is proving soundness properties for the deduction rules allowing polymorphism on input, rather than a more general basis for studying programming with session types.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Proposed Approach}\label{sec:approach}

%% state how you propose to solve the software development problem. Show that
%% your proposed approach is feasible, but identify any risks.

I intend to mechanise the calculi described by \citeauthor{Wadler:2012}~\cite{Wadler:2012} using the Coq proof assistant. In the spirit of the POPLMARK challenge, I aim to utilise available libraries and infrastructure as much as possible. \citeauthor{Aydemir:2008:EFM}~\cite{Aydemir:2008:EFM} developed a metatheory library for handling, among other things, association lists (environments) and free variable representation. I intend to use the version distributed by~\citeauthor{Park:2014:MMW}~\cite{Park:2014:MMW} which has been updated for Coq version 8.4pl4. \citeauthor{Park:2014:MMW} describe a technique for removing nonlinear contexts from typing judgements. While their work extended to \fpop it is not clear how to handle an environment containing both non-linear and linear types as in GV. I wish to maintain as close a relationship as possible to the paper system presented by \citeauthor{Wadler:2012}, so separating out the non-linear and linear components (as in \fpop) is not an option at this stage.

Following \citeauthor{Aydemir:2008:EFM}~\cite{Aydemir:2008:EFM}, I use the locally nameless first-order representation for binders and free variables, preventing variable capture issues present in other first-order representations. Likewise, I make some simplifying assumptions about variable substitution, namely that \textit{closed} terms (terms with no unbound indices) are substituted for variables, which avoids having to define lifting constructs on the substitute term. The typing rules will not contain a rule for an unbound index so this decision is sound. A consequence is that we must define a notion of opening language terms involving binders as described by~\citeauthor{Aydemir:2008:EFM}. For example, an abstraction with body term $t$ which is well-typed if $t$ is well-typed when its unbound index, representing the argument to the abstraction, is replaced by some fresh variable $x$, written $t^x$. Some terms in GV require multiple binders but I believe it will be straightforward to extend this notion. Unfortunately, I must define similar operations on CP terms and handle substitution and opening on them as well as propositions which can accept propositional variables. I hope to be able to generalise as much as possible with the help of the Metatheory library. Alternatively, I could have chosen a higher-order abstract syntax (HOAS) approach such as the parametric version (PHOAS) described by~\citeauthor{Chlipala:2008:PHOAS}~\cite{Chlipala:2008:PHOAS}. PHOAS relies on the metalanguage (Coq, in this case) for handling binders and substitution so has less overhead in managing syntax than the locally nameless approach. However, variables are now parameters defined at the level of the metalanguage so can represent terms not valid in the language being mechanised. Further, a higher-order approach would prevent the use of the Metatheory library which provides a number of useful tactics for manipulating typing contexts.

For handling binder freshness, I chose to adopt the cofinite quantification approach described by~\cite{Aydemir:2008:EFM}~\cite{Aydemir:2008:EFM}, which excludes a finite set of variables from being considered as the binder. In contrast, the traditional ``exists-fresh'' approach, where the binder is only required to be fresh within the abstraction's body, does not produce strong enough induction principles in some cases.

While the aim is to be faithful to \citeauthor{Wadler:2012}'s description, I may need to alter the approach slightly to avoid tricky formulations. For instance, instead of providing n-ary branch and choice in GV, we provide only binary versions of these operators to simplify the development. This change is not restrictive however, since CP itself provides only binary versions of plus ($\oplus$) and with ($\with$) constructs. Likewise, on a more technical note, we amalgamate all types into one inductive definition and provide a predicate for restricting typing rules to consider only valid session types. \citeauthor{Wadler:2012} defines GV types as a set of mutually recursive definitions; session types are types which may contain types as subcomponents (arguments to send, for example). Unfortunately, handling mutually inductive definitions in Coq can be quite involved; requiring one to either rely on the Coq system to provide a stronger mutual induction principle or defining one manually. Such a definition is possible, but it complicates elimination via the induction principle.
% ( since the standard induction tactic will not work?)

Another aspect of the encoding is how to define terms. The intrinsic encoding described by~\citeauthor{Benton:2012:STT}~\cite{Benton:2012:STT} is one approach, indexing terms by their type so as to prevent ill-formed terms from being constructed. However, in the encoding for GV there are issues with using this encoding: $(1)$ it is not immediately clear how to handle linear contexts using the de Bruijn variable encoding, since in the intrinsic setting the environment supports weakening; $(2)$ an intrinsic encoding of terms would be complicated by the need to enforce that session types occur in certain instances (by use of a predicate); and $(3)$ well-typed terms require extra assumptions about binder freshness which cannot reasonably be expressed as a function type. For these reasons, an intrinsic approach does not offer much benefit since a well-typed term relation would still need to be defined. Therefore, I chose an extrinsic encoding for terms and define well-typed terms as a separate inductive type.

\citeauthor{Aydemir:2008:EFM}~\cite{Aydemir:2008:EFM} note that the size of their language proof infrastructure is proportional to the number of binding constructs. In the case of a simply typed lambda calculus this is not onerous, but GV has four binding constructs, CP has six and propositions have two. It may be true that this approach results in too many auxiliary definitions and operations not relevant to the actual properties one wishes to prove. However, I believe that once this infrastructure has been defined, the system can be extended without concern for these binding constructs.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Work Plan}

I aim to have completed the GV and CP definitions including reduction and commuting conversion rules for CP by the end of December. This will require definition of infrastructure for handling binders for both GV, CP channels and CP propositional variables, and inductive definitions for well-typed terms, commuting conversions and CP principal cut reductions. So far I have completed some of the definitions for well-typed terms and CP process rules; the remaining rules require the infrastructure for substitution and opening of binders.

After December, it remains to define the translation between GV and CP which I envisage will be the bulk of the work, requiring several rules on typing derivations; I envisage being able to define these as inductive datatype constructors but I shall take care to reuse any suitable libraries that are available, e.g. a library for handling CPS translations.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\printbibliography

\end{document}
