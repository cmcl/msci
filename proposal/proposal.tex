\documentclass{mprop}

% Include Coq lstlisting language definition and things upon which it depends.
\usepackage{macros}
\usepackage{hyperref}

\usepackage{listings}
\usepackage{lstcoq}
\usepackage{graphicx}
\usepackage{xspace}
\usepackage{cmll}
\usepackage{prooftree}
\usepackage{amsmath}
\newcommand{\typestate}[2]{{#1}\gg{#2}}
\usepackage[style=alphabetic,sorting=nymt,natbib=true,
  maxbibnames=100]{biblatex}

\DeclareSortingScheme{nymt}{
  \sort{
    \field{author}
    \field{year}
    \field{month}
    \field{title}
  }
}

% Thanks to Stefan Kottwitz on tex.stackexhange.com:
% http://tex.stackexchange.com/questions/69662/how-to-globally-change-the-spacing-around-equations
%% \expandafter\def\expandafter\normalsize\expandafter{%
%%     \normalsize
%%     \setlength\abovedisplayskip{0pt}
%%     \setlength\belowdisplayskip{0pt}
%%     \setlength\abovedisplayshortskip{0pt}
%%     \setlength\belowdisplayshortskip{0pt}
%% }

\addbibresource{proposal.bib}

\input{propmacros}

\allowdisplaybreaks

% alternative font if you prefer
%\usepackage{times}

% for alternative page numbering use the following package
% and see documentation for commands
%\usepackage{fancyheadings}

\newcommand{\fpop}{System F${}^\circ$\xspace}

% other potentially useful packages
%\uspackage{amssymb,amsmath}
%\usepackage{url}
%\usepackage{fancyvrb}
%\usepackage[final]{pdfpages}

\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{Mechanisation of Session-based Lambda Calculus Type Systems}
\author{Craig McLaughlin}
\date{\today}
\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\tableofcontents
\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}\label{intro}

Two aspects of programming language research are relevant for this
project. The first is concerned with static type systems for ensuring runtime
safety properties for concurrent communication systems. The second is the
increasing use of proof assistants and interactive theorem provers for
studying and mechanically verifying the semantics and properties of
programming languages.

\subsection{On Communication}

Distributed communication systems are becoming increasingly prevalent in
modern society. To facilitate communication between concurrently executing
agents requires complex network protocols to define the type and sequencing of
messages. Typically these protocols are implemented in systems programming
languages, such as C, which provide no correctness guarantees of the
implementation. Furthermore, programming in these languages is often extremely
error-prone, as one has a myriad of unsafe features at one's disposal. As more
businesses begin to conduct transactions over the Web, it is imperative that
they can reason about the communication protocols upon which they rely.

Encoding communication protocols as \textit{session types} is one approach to
achieve guarantees about correctness. One particular variant of session types
are \textit{binary} session types~\footnote{There are also \textit{multiparty}
 session types, but I do not discuss them here.}. A binary session type
specifies communication between two agents, and it specifies the order and
type of messages to be sent or received by an agent in the system. The two
agents have dual session types such that, for example, when one is expecting
to receive a message the other is expecting to send a message; both session
types agree on the type of message to be exchanged. In this way, correctness
of communication can be statically assured by providing communicating agents
with a \textit{channel} whose endpoints have dual session types. A channel is
defined as a bi-directional conduit for exchanging messages, not unlike a
socket in network programming. In contrast to sockets, however, a channel is
associated with an explicit type which provides a description of its
protocol. Thus, in session-based systems a channel is usually provided as a
primitive type.

\subsection{On Verification}

In programming language research, work on static type systems is usually
presented on paper complete with informal proofs of correctness for the system
properties. Most types systems in the session types community have been
developed in this way. However, it is more difficult to extend work using this
approach, as it may be unclear how changes affect proofs and one will
typically have to re-consider all proofs to be convinced the properties still
hold. More generally, unassisted formalisms are error-prone to develop and do
not provide a firm basis upon which other researchers can experiment; often it
will require ``rolling your own'' compiler for the language of interest.

Proof assistants such as Coq~\cite{Coq:manual} offer a platform on which to
develop programming languages and type systems and associated proofs of
properties with strong guarantees of correctness. Not only is proving with a
proof assistant much less error-prone than the unaided approach, it also eases
extension of the system since the proof assistant will highlight parts of
proofs that have been affected by changes. However, one may have to prove more
properties using this approach since this setting does not permit appealing to
human intuition. For example, alpha-equivalence and freshness of binders are
usually assumed in informal presentations, whereas in the mechanised setting
one has to explicitly encode and reason about these
properties~\cite{Aydemir:2005:MMM, Aydemir:2008:EFM}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Statement of Problem}

The aim of this project is to develop a framework for formalising lambda
calculus type systems involving session types using interactive theorem
proving (in particular, the system Coq). The motivation for the framework is
that it will enable a whole class of related languages and type systems to be
formalised with little extra proof effort. Inspired by previous work on a
mechanised framework for $\pi$-calculus type systems~\cite{Gay:2001:FFP}, I
shift to the lambda calculus to provide a basis on which session types for
mainstream programming languages can be studied, whilst taking advantage of
previous proof effort and specialising only for those parts unique to the
particular system. The framework will be heavily based on calculi developed by
\citeauthor{Wadler:2014}~\cite{Wadler:2014} describing a relationship between
classical linear logic (CP) and a functional language with session types
(GV). GV is a minimal functional language supporting linearity so I believe
such a basis will be general enough to support reasoning about a large class
of functional languages with similar base properties.

From this framework, a number of directions can be explored including session
polymorphism session subtyping, and permitting different forms of aliasing
within the type system. The recent work by \citeauthor{Lindley:2014:SAP}
\cite{Lindley:2014:SAP}, who extend GV to HGV supporting session forwarding,
replication and polymorphism, would be an interesting place to start when
looking to add these extensions.

Additionally, the majority of previous session type systems for mainstream
programming languages have focussed exclusively on linear type systems. One
disadvantage of a linear type system is the need to re-bind objects after each
operation~\cite{Gay:2010:LAST}. One could extend the GV type system to provide
the benefits of aliasing with the guarantees of linearity which has been
studied in several systems using a variety of alias control
methods~\cite{Fahndrich:2002,Mazurak:2010:LLT,Tov:2011}. Another approach,
which has been utilised in previous session-based $\lambda$-calculus type
systems, is to support side-effecting functions by allowing functions to close
over channels in the environment~\cite{Gay:2003:STI,Vasconcelos:2006:TCM}. An
interesting extension to the base GV type system would be to incorporate the
closure semantics into the type system which would permit functions to modify
session-typed channels in the environment. The typing rules would be similar
to that described by \citeauthor{Gay:2010:MST} for typing expressions in an
object-oriented setting for session types~\cite{Gay:2010:MST}, e.g. the rule
for lambda abstraction could be:
\begin{gather*}
  \frac{
    \typeds{\Gamma,\typedid{x}{A}}{t}{T}{\Gamma',\typedid{x}{B}}
  }{
    \typeds{\Gamma}{\abs{x}{t}}{\fn{\typestate{A}{B}}{T}}{\Gamma'}
  }\quad
\end{gather*}

The $\Gamma$, $\Gamma '$ environments represent pre and post-states of
variables satisfied by term $t$. The typing for the function argument is
inspired by typestate-oriented programming~\cite{Aldrich:2009} and says that
the function expects a channel behaving according to protocol $A$ and alters
the state of the channel internally producing a channel behaving according to
protocol $B$. It remains to be seen whether such typing rules can be encoded
as described in the GV setting.

These extensions will argue that the framework supports a wide range of
languages and type systems, providing researchers the ability to harness the
power of formal verification in the design, implementation and documentation
of session-based type systems.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Background Survey}

%% present an overview of relevant previous work including articles, books,
%% and existing software products. Critically evaluate the strengths and
%% weaknesses of the previous work.

The background for this project can be categorised roughly as previous work on
session-based type systems (sub-divided into $\pi$ and $\lambda$-calculi
variants, \S \ref{sec:pis} and \S \ref{sec:lam}, respectively) and previous
work on formal verification using proof assistants (particularly focussed on
programming language mechanisation). Finally, some recent work has merged
these two disciplines by verifying a session-based $\pi$-calculus system (\S
\ref{sec:asts}).

\subsection{Session-based Type Systems and Linear Logic}\label{sec:sts}

\subsubsection{In the \texorpdfstring{$\pi$}{pi}-calculus}\label{sec:pis}

\citeauthor{Caires:2010:STI} \cite{Caires:2010:STI} present a connection
between a $\pi$-calculus type system with session types ($\pi$DILL) and dual
intuitionistic linear logic (DILL)~\cite{Barber:1996}. They equate linear
propositions with session types of the process calculus via a bidirectional
translation relation. They use a binary reduction relation and a labelled
transition system to represent process reduction and process action with its
environment as is standard~\cite{Sangiorgi:2001}.

They represent dual intuitionistic linear logic as a sequent calculus
providing logical connectives which have session-based interpretations in
$\pi$DILL. Consider their rules for branch and choice in $\pi$DILL:
\input{sill-branch-choice-rules}

Note that branch and choice both have some notion of branching (R rules for
$\oplus$/L rules for $\with$) and at least for \& this is counter-intuitive in
a session-based setting, since the intutition for \& is that of
\emph{offering} a choice between alternatives rather than \emph{making} the
choice. Here, however, the intuition should be extended to account for its
location in the typing judgement. The channel is on the left of the sequent,
and \citeauthor{Caires:2010:STI} suggest one consider the context as services
being provided to the typed process. Thus, the type of channels in the context
is really the type of the other endpoint of the channel, and the typed process
behaves according to the dual protocol. For example, considering
$\SILLbranchLTwo$, and taking $A^\bot$ to represent the dual of a protocol $A$
as defined by \citeauthor{Wadler:2014}~\cite{Wadler:2014}, the typed process
is behaving according to the protocol $\BChoice{A^\bot}{B^\bot}$, selecting
from alternatives (in this case, $\inrterm$) and then behaving according to
the selected protocol (in this case, protocol $B^\bot$).

As noted by Wadler~\cite{Wadler:2014} there is a certain amount of redundancy
in the two-sided nature of the rules forcing one to commit to a certain
convention when typing a communication system. Consider, an equivalent system
to the buy/quote example given by
\citeauthor{Caires:2010:STI}~\cite[\S~3]{Caires:2010:STI}:
\begin{gather*}
\sdef{ClientProto}{\BChoice{(\tensor{Book}
                            {(\tensor{Card}{(\lfn{Receipt}{\1})})})}
                           {(\tensor{Book}{(\lfn{Quote}{\1})})}}
\end{gather*}

In the protocol defined above, a client selects between buying a book or
receiving a price quote for a book. In the buy option case, the client sends
the name of the book to the server and their card details, then the server
sends the receipt for the purchase. In the quote option case, the client sends
the name of the book and receives a price quote from the server. I have
replaced the types $N$ and $I$ used by \citeauthor{Caires:2010:STI} with more
meaningful type names $Book$, $Card$, $Quote$ and $Receipt$ where appropriate;
all are synonyms for the type $\1$ which denotes the terminal session
type. The client and server process bodies are as follows:
\begin{gather*}
\sdef{ClientBody_c}
     {\CPinr{c}{\SLoutput{1984}{c}{\SLinput{c}{quote}{\0}}}}\\
\sdef{ServerBody_c}
     {\CPcase{c}
             {\SLinput{c}{book}{\SLinput{c}{card}{\SLoutput{receipt}{c}{\0}}}}
             {\SLinput{c}{book}{\SLoutput{quote}{c}{\0}}}}
\end{gather*}

\begin{samepage}
The typings for the client and server processes are given by:
\begin{gather*}
\tsequent{\cdot}{\cdot}{ClientBody_c}{\typedid{c}{ClientProto}}
\tag{\mkTrule{ClientBody}} \label{eq:cbtyp}
\\ \tsequent{\cdot}{\typedid{c}{ClientProto}}{ServerBody_c}{\typedid{-}{\1}}
\tag{\mkTrule{ServerBody}} \label{eq:sbtyp}
\end{gather*}
\end{samepage}

The derivation for \eqref{eq:cbtyp} is $T\1 R$, $\lfn{T}{R}$, $\tensor{T}{R}$,
$\BChoice{T}{R_2}$ and \eqref{eq:sbtyp} is derivable from
$\BChoice{T}{L}$. Except for the final rule, these are exact dual rules of the
rules used in example by \citeauthor{Caires:2010:STI}. Indeed, consider the
composite process:
\begin{gather*}
\sdef{QSimple}{\Spar{c}{ClientBody_c}{ServerBody_c}}\\
\tsequent{\cdot}{\cdot}{QSimple}{\typedid{-}{\1}}
\end{gather*}

The final system is near identical to the one produced in the example given by
\citeauthor{Caires:2010:STI} except the individual processes within the
parallel composition have been swapped. Here the client communicates along the
channel $c$ on the right-side of the sequent and the server utilises the
channel $c$ on the left of the sequent. This typing, while correct, violates
the intuition given by \citeauthor{Caires:2010:STI} of the context providing
the services used by the process, since one would usually associate provision
of services with the server not the client. Instead, the example above
suggests the server utilises some channel provided by the client. On the other
hand, one could imagine such a channel being setup between two communicating
agents; the ``owner'' of the channel is largely irrelevant. Note that
$ClientProto$ is in fact the dual of the $ServerProto$ definition by
\citeauthor{Caires:2010:STI} using the definition of dual used in Wadler's
classical process calculus~\cite{Wadler:2014}. In $\pi$DILL, the duality
between endpoints of the same channel are obscured by the nature of the typing
judgements.

Process reduction steps are equated with proof reduction via cut
elimination. The relationship with proof normalisation in DILL provides
absence of deadlocks in session-based communication for the process
calculus. The correspondence of session types to linear logic propositions is
an important step in providing a solid logical foundation for a concurrent
type theory; in the same way ``sequential'' type theory ($\lambda$-calculi)
profitted from a logical perspective. However, for session types to become a
more usable tool for programming distributed communication systems (the
ultimate goal, of course, is to write more correct programs), we cannot be
expected to program directly in the $\pi$-calculus; a more mainstream
programming paradigm must be built upon these solid logical foundations. With
that in mind, enter the $\lambda$-calculus!

\subsubsection{In the \texorpdfstring{$\lambda$}{lambda}-calculus}
\label{sec:lam}

A series of works by \citeauthor{Gay:2003:STI}~\cite{Gay:2003:STI} and
\citeauthor{Vasconcelos:2006:TCM}~\cite{Vasconcelos:2006:TCM} provide a
$\lambda$-calculus based language with session types for channel
primitives. The type system is nonstandard, featuring an additional
environment for tracking the session types of channels; these types are
modified during term reduction to reflect communication. The extra channel
environment is provided to support possible aliasing of channels by treating
channel variables as pointers or references into the channel environment. So,
for a channel $c$ of session type $S$, a variable $x$ referring to this
channel would be declared to have type $Chan~c$ and $c~:~S$ would be in the
channel enviornment. The typing judgements and term reduction relation must be
augmented to handle these environments. Unfortunately, a side-effect of this
is that function types must specify the pre and post-states of channel
environments and therefore, the type of arguments cannot work up to
alpha-equivalence of channel identifiers. That is, if two channels $c$ and $d$
have the same session type, one cannot define a function to operate on
variables of either channel type since the function definition will explicitly
mention the identifier for the channel (in this case either, $Chan~c$ or
$Chan~d$). However, the system does provide an attractive non-linear channel
type which has been neglected in favour of a linear treatment of channels in
more recent
works~\cite{Gay:2010:LAST,Mazurak:2010:LCC,Wadler:2014}. Certainly, it is the
case that an aliased approach would fit better with mainstream programming
languages and perhaps studying a similar system could offer some insights.

The ``adoption and focus'' system~\cite{Fahndrich:2002} provides a notion of
aliased access to linear resources. The type system requires special language
features, e.g. to manage capabilities which can be thought as a form of object
liveness mechanism, so GV typing judgements would need to be extended such
that the capabilities can be included in soundness results. A extension to the
translation to CP to incorporate the ``adopt'' and ``focus'' constructs would
also need to be defined. It is not immediately clear how these features would
assist in the management of session typed channels. The ``focus'' rule (and
linearity generally) enforces an invariant on the focussed object (channel)
such that the type is maintained during the focus operation:

... copy of focus operation here ...

Such a rule would appear to only benefit recursive session types. Indeed,
focussing on a non-recursive channel would be pointless since one would be
prevented from communicating across it since the focus rule requires
maintenance of the channel type. Further, it would be undesirable to permit
modification of a session type without guaranteeing exclusive access to the
channel since this could lead to invalid communication e.g. trying to
communicate on a closed channel. Additionally, a linear object is consumed
upon being adopted and will be deallocated when its adopter's lifetime ends,
although an alternative semantics could be defined which returned the linear
resource to the context. Moreover, \citeauthor{Fahndrich:2002} do not provide
operational semantics or soundness results for the ``adoption and focus'' type
system.

The Alms language~\cite{Aldrich:2009} provides a functional language with
affine types based on linear logic. A notion of type \textit{kind} is used to
distinguish between affine and unrestricted values. The typing judgements use
two contexts; one for variables with unrestricted kind and another for
variables of affine type and type variables. Functions are also labelled with
a kind which may depend on their arguments e.g. a multiple argument function
must have affine kinding if it accepts an affine typed resource as an argument
other than the final argument. The reason for this is simply to prevent the
function from using an affine resource more than once. Additionally, functions
act as closures over their environments so their qualifier may be determined
by a free variable in the environment, and a relation is provided to calculate
the appropriate kind qualifier. Type variables are provided to support kind
polymorphism of function qualifiers. The system is expressive enough to
implement session types as a module using a similar approach to
\citeauthor{Gay:2010:LAST}~\cite{Gay:2010:LAST} although treating channels as
affine rather than linearly typed. \citeauthor{Aldrich:2009} note that Alms'
type system can support the ``adoption and focus'' system but do not specify
details or whether any changes are necessary to their typing judgements.

The work on a linear functional language with session types by
\citeauthor{Gay:2010:LAST}~\cite{Gay:2010:LAST} is the main influence for the
current project from the body of work on session-based $\lambda$-calculus type
systems. They provide paper proofs of their system's type safety. Given the
non-trivial features of the type system such as recursive session types and
buffered channels for supporting asynchronous communication it will be
challenging to extend these proofs manually. A mechanised version would
provide stronger guarantees of correctness and allow others to more easily
alter proofs as a result of changes made to the language.

\subsubsection{Fusion}

A number of systems incorporate both a functional language surface syntax with
a translation to a more primitive process calculus. We shall focus on two such
systems presented recently which have a connection to linear logic.

Lolliproc~\cite{Mazurak:2010:LCC} provides a functional language with
concurrency primitives as a surface syntax on top of an underlying process
calculus. The process calculus provides a classical linear logic
interpretation for the functional language, utilising double negation
elimination to provide session type duality. The surface syntax is an
effective abstraction layer for the programmer since it does not expose the
underlying process calculus.

Concurrency is provided by control operators which, respectively, spawn a
child process and wait for a child process to complete. The spawning process
creates a channel between parent and child process; a channel is represented
as a continuation and the type denotes the communication protocol
(i.e. session type) between parent and child.

\citeauthor{Mazurak:2010:LCC} present proofs for type safety, strong
normalisation and confluence. Confluence provides the guarantee that no race
conditions can occur, strong normalisation prohibits nonterminating programs
and type safety assures deadlock-freedom. Deadlock-freedom is implied by the
acyclic communication graphs (progress of process reduction) which occur
between parallel processes; follows from permitting only one channel between
two halves of parallel composition construct in the process calculus. Most of
the development is supported by Coq proof scripts with remaining issues due to
reasoning about communication graphs. The development does not provide
primitive send and receives; instead, these are encoded as linear functions.
%% and classical extension to second-order logic by
%% \citeauthor{Mazurak:2013:LPP}'s PhD thesis~\cite{Mazurak:2013:LPP}.

\citeauthor{Wadler:2014}'s recent work~\cite{Wadler:2014} brings together a
process calculus, CP, based on the earlier work by
\citeauthor{Caires:2010:STI} with a functional language, GV, based on LAST by
\citeauthor{Gay:2010:LAST}. The work describes a continuation-passing style
(CPS) translation from GV to CP treating session types as propositions in a
classical linear logic. The process calculus is slightly different to that
described by $\pi$DILL~\cite{Caires:2010:STI}, apart from being classical in
nature, the constructs for server replication are modified; CP provides a
weakening and contraction rules whereas these are encoded in one rule for
process reduction by \citeauthor{Caires:2010:STI}. Additionally, rather than a
two-sided sequent calculus, \citeauthor{Wadler:2014} uses one-sided sequents
for defining the process calculus, which provides a more intuitive
presentation of session type duality and clearer correspondence to a
$\lambda$-calculi surface syntax. As presented, GV does not support all
features of CP and thus the translation is one way (GV to
CP). \citeauthor{Lindley:2014:SAP}~\cite{Lindley:2014:SAP} extend GV to
provide support for polymorphism and replication, following a similar CPS
translation scheme. Lastly,
\citeauthor{Lindley:2014:SPS}~\cite{Lindley:2014:SPS} describe operational
semantics for GV and their system has greater similarities with LAST than
prior GV works, for example, by treating send and receive as linear functions
rather than language primitives.

%% Wadler also dispenses with the structural rules; subsumed by the Assoc and
%% Swap typing derivations and the cut reduction (double check why he does
%% this)

\subsection{Mechanising Programming Language Metatheory}

Interactive theorem proving and proof assistants have seen an upsurge in use
in recent years. Especially within the domain of programming language
research, there is a strong emphasis on providing mechanised proofs
accompanying work in the area. Indeed, \citeauthor{Aydemir:2005:MMM} have
published a series of challenges on mechanising programming languages aimed at
providing a starting point for comparing different representation
techniques~\cite{Aydemir:2005:MMM}. Another aim is to provide reusable
libraries for common reasoning needed across programming language
developments, e.g. handling of typing environments. This effort has resulted
in a number of different approaches for representing programming languages
within proof assistants. For instance,
\citeauthor{Aydemir:2008:EFM}~\cite{Aydemir:2008:EFM} present a representation
of $\lambda$-calculi where bound variables are represented as \textit{de
  Bruijn indices}~\footnote{A de Bruijn index is a number used to represent a
  bound variable which indicates the position of its binder (starting from
  zero for the innermost binder). For example, $\lambda~(\lambda~1)$
  corresponds to $\lambda x. \lambda y. x$, i.e. the constant function.} and
free variables are represented as named terms; the \textit{locally nameless}
representation. Their work resulted in a library for handling commonly
occurring aspects in programming language metatheory which has been used since
in other developments~\cite{Park:2014:MMW}. Reusable libraries reduce the
proof engineering effort needed for later works, in contrast to the
pen-and-paper approach, and some proof assistants (as is the case with Coq)
allow one to extract a program from the development which can provide a
typechecker or compiler for the language formalised.~\footnote{Curry-Howard
  strikes again; a proof of decidability of typechecking corresponds to a
  program implementing a typechecker for the language.}

Some recent mechanisation effort focuses on providing a basis for studying
linearity within type systems. This work is of interest to the current project
since most session-based type systems assume a strictly linear type system
which requires re-binding of channel identifiers, such as in the functional
setting of \citeauthor{Gay:2010:LAST}. \citeauthor{Mazurak:2010:LLT} present
an extension to System F (termed \fpop) with a notion describing types as
having linear or non-linear \textit{kind}~\cite{Mazurak:2010:LLT}. This
extension is motivated by previous work on incorporating linearity into type
systems. Overall, previous attempts either hamper the inclusion of desirable
programming features (such as polymorphism), or do not adequately reflect
non-linearity as the common case leading to awkward programming. \fpop avoids
these deficiencies by categorising types into kinds whilst maintaining similar
semantics to System F. Mechanised proofs for type soundness and parametricity
are presented, and the semantics allow non-linear types to be treated as
linear. Examples show the system can provide a wide range of permissions on
interfaces, from full exclusive access to read-only shared references. The
system is very close to the Alms language described by
\citeauthor{Aldrich:2009} but has the advantage that the soundness results
(type safety and parametricity) have been entirely mechanised in Coq. It would
be interesting to see if one could encode the ``adopt'' and ``focus''
constructs in this system to compare its expressiveness to Alms. The ``adopt''
rule can be encoded similarly to the ShareRef
example~\cite{Mazurak:2010:LLT}. It is not immediately clear how to encode the
``focus'' rule within the present semantics, as one needs to prevent
non-linear access to its argument implying the presence of knowledge about
aliasing within the typing judgements; absence of aliasing is not identified
with linear kinded types in \fpop.

While not related to programming language metatheory,
\citeauthor{Gay:2001:FFP}~\cite{Gay:2001:FFP} provides a $\pi$-calculus
framework mechanised in Isabelle/HOL. The aim is to build a mechanisaton of
session-based type systems on top of the $\pi$-calculus framework. The use of
de Bruijn indices for both bound and free variables causes issues with
variable substitution often requiring permutation of typing environments (see
\citeauthor{Aydemir:2008:EFM}~\cite{Aydemir:2008:EFM} for a discussion on
binder representations) and lifting of free variables during substitution; I
avoid this issue in my representation choice (\S \ref{sec:approach}).

The introduction of names for hypotheses during execution of custom tactics
are an issue in the proof development. These names are automatically generated
by the Isabelle/HOL system which creates a dependency between the names chosen
and the tactic. Thus, one must be careful to use the exact names expected by
the tactic. In the Coq proof assistant, defining custom tactics can be
achieved using the Ltac language~\cite{Delahaye:2000:TLS}. Among other things,
Ltac supports pattern matching on hypotheses and goal forms. Thus, if we
wished to pattern match on an inductive type describing variables, we could do
so without mentioning the actual variable name as follows:

\begin{coq}
Ltac my_tactic :=
  match goal with
  | [v: var |- _] => ... tactics here possibly mentioning `v' hypothesis ...
  end.
\end{coq}

\subsubsection{Applications to Session-based Type Systems}\label{sec:asts}

\citeauthor{Goto:2014}~\cite{Goto:2014} provide a $\pi$-calculus session-based
type system providing session polymorphism. The system is more general than
session polymorphism via subtyping~\cite{Gay:2005:SST} in that it is capable
of typing a generic forwarding process between mutually dual session
types. Defining such a process is not possible using subtyping since one
wishes to restrict the types to be dual, not a subtype of some other
type. This more general form of polymorphism is achieved by permitting input
on all session types (including \lstinline{end}, the terminal session type)
and then employing transition hypotheses to ensure the type permits such
input. The authors mechanise their type system and its properties in the Coq
proof assistant. However, the mechanised system is restricted to the
$\pi$-calculus and the main focus is proving soundness properties for the
deduction rules allowing polymorphism, rather than a more general basis for
studying programming with session types.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Proposed Approach}\label{sec:approach}

%% state how you propose to solve the software development problem. Show that
%% your proposed approach is feasible, but identify any risks.

I intend to mechanise the calculi described by
\citeauthor{Wadler:2014}~\cite{Wadler:2014} using the Coq proof assistant. In
the spirit of the POPLMARK challenge, I aim to utilise available libraries and
infrastructure as much as
possible. \citeauthor{Aydemir:2008:EFM}~\cite{Aydemir:2008:EFM} developed a
metatheory library for handling, among other things, association lists
(environments) and free variable representation. I intend to use the version
distributed by~\citeauthor{Park:2014:MMW}~\cite{Park:2014:MMW} which has been
updated for Coq version 8.4pl4. \citeauthor{Park:2014:MMW} describe a
technique for removing nonlinear contexts from typing judgements. While their
work extended to \fpop it is not clear how to handle an environment containing
both non-linear and linear types as in GV. I wish to maintain as close a
relationship as possible to the paper system presented by
\citeauthor{Wadler:2014}, so separating out the non-linear and linear
components (as in \fpop) is not an option at this stage.

Following \citeauthor{Aydemir:2008:EFM}~\cite{Aydemir:2008:EFM}, I use the
locally nameless first-order representation for binders and free variables,
preventing variable capture issues present in other first-order
representations. Likewise, I make some simplifying assumptions about variable
substitution, namely that \textit{closed} terms (terms with no unbound
indices) are substituted for variables, which avoids having to define lifting
constructs on the substitute term. The typing rules will not contain a rule
for an unbound index so this decision is sound. A consequence is that we must
define a notion of opening language terms involving binders as described
by~\citeauthor{Aydemir:2008:EFM}. For example, an abstraction with body term
$t$ which is well-typed if $t$ is well-typed when its unbound index,
representing the argument to the abstraction, is replaced by some fresh
variable $x$, written $t^x$. Some terms in GV require multiple binders but I
believe it will be straightforward to extend this notion. Unfortunately, I
must define similar operations on CP terms and handle substitution and opening
on them as well as propositions which can accept propositional variables. I
hope to be able to generalise as much as possible with the help of the
Metatheory library.

Alternatively, I could have chosen a higher-order abstract syntax (HOAS)
approach such as the parametric version (PHOAS) described
by~\citeauthor{Chlipala:2008:PHOAS}~\cite{Chlipala:2008:PHOAS}. PHOAS relies
on the metalanguage (Coq, in this case) for handling binders and substitution
so has less overhead in managing syntax than the locally nameless
approach. However, variables are now parameters defined at the level of the
metalanguage so can represent terms not valid in the language being
mechanised. Further, a higher-order approach would prevent the use of the
Metatheory library which provides a number of useful tactics for manipulating
typing contexts.

For handling binder freshness, I chose to adopt the cofinite quantification
approach described by~\cite{Aydemir:2008:EFM}~\cite{Aydemir:2008:EFM}, which
excludes a finite set of variables from being considered as the binder. In
contrast, the traditional ``exists-fresh'' approach, where the binder is only
required to be fresh within the abstraction's body, does not produce strong
enough induction principles in some cases. This change will necessitate
changes to the typing rules of GV and CP. Consider for instance the Connect
rule in GV~\cite{Wadler:2014} (Connect) and its corresponding cofinite
quantification version (ConnectCO):

... connect with rule here ... ... connect rule using cofinite quantification

The conclusion binds a variable in Connect but a type in ConnectCO. Thus, in
the premise for ConnectCO one can choose a suitably fresh $x$. The same change is made to the rules for CP so that, for example, output which allocates a fresh variable $y$ no longer names $y$ in the conclusion:

... output in CP ... ... version used here with cofinite quantification ...

Since the name $y$ is assumed to be fresh in the original presentation these
changes do not alter the typing of processes nor the semantics of the
translation from GV to CP. An equivalence between ``exists-fresh'' and
cofinite quantification definitions of the simply-typed $\lambda$ calculus is
given by \citeauthor{Aydemir:2008:EFM}~\cite{Aydemir:2008:EFM}. In general, I
do not aim to formally prove adequacy of the mechanisation.

While the aim is to be faithful to \citeauthor{Wadler:2014}'s description, I
may need to alter the approach slightly to avoid tricky formulations. For
instance, instead of providing $n$-ary branch and choice in GV, we provide
only binary versions of these operators to simplify the development. This
change is not restrictive however, since CP itself provides only binary
versions of plus ($\oplus$) and with ($\with$) constructs. Likewise, on a more
technical note, I amalgamate all types into one inductive definition and
provide a predicate for restricting typing rules to consider only valid
session types. \citeauthor{Wadler:2014} defines GV types as a set of mutually
recursive definitions; session types are types which may contain types as
subcomponents (arguments to send, for example). Unfortunately, handling
mutually inductive definitions in Coq can be quite involved; requiring one to
either rely on the Coq system to provide a stronger mutual induction principle
or defining one manually. Such a definition is possible, but it complicates
elimination via the induction principle.
% ( since the standard induction tactic will not work?)

Another aspect of the encoding is how to define terms. The intrinsic encoding
described by~\citeauthor{Benton:2012:STT}~\cite{Benton:2012:STT} is one
approach, indexing terms by their type so as to prevent ill-formed terms from
being constructed. However, in the encoding for GV there are issues with using
this encoding: $(1)$ it is not immediately clear how to handle linear contexts
using the de Bruijn variable encoding, since in the intrinsic setting the
environment supports weakening; $(2)$ an intrinsic encoding of terms would be
complicated by the need to enforce that session types occur in certain
instances (by use of a predicate); and $(3)$ well-typed terms require extra
assumptions about binder freshness which cannot reasonably be expressed as a
function type. For these reasons, an intrinsic approach does not offer much
benefit since a well-typed term relation would still need to be
defined. Therefore, I chose an extrinsic encoding for terms and define
well-typed terms as a separate inductive type.

\citeauthor{Aydemir:2008:EFM}~\cite{Aydemir:2008:EFM} note that the size of
their language proof infrastructure is proportional to the number of binding
constructs. In the case of a simply typed lambda calculus this is not onerous,
but GV has four binding constructs, CP has six and propositions have two. It
may be true that this approach results in too many auxiliary definitions and
operations not relevant to the actual properties one wishes to prove. However,
I believe that once this infrastructure has been defined, the system can be
extended without concern for these binding constructs.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Work Plan}

I aim to have completed the GV and CP definitions including reduction and
commuting conversion rules for CP by the end of December. This will require
definition of infrastructure for handling binders for both GV, CP channels and
CP propositional variables, and inductive definitions for well-typed terms,
commuting conversions and CP principal cut reductions. So far I have completed
some of the definitions for well-typed terms and CP process rules; the
remaining rules require the infrastructure for substitution and opening of
binders.

After December, it remains to define the translation between GV and CP which I
envisage will be the bulk of the work, requiring several rules on typing
derivations; I plan to define these as inductive datatype constructors but I
shall take care to reuse any suitable libraries that are available, e.g. a
library for handling CPS translations. For this step of the work, I allocated
one month but this is a cautious estimate accounting some slack time for any
delays in preceding stages of the development; I suspect this stage will not
require a full month.

For the remainder, I shall look to extend the definitions of GV and CP using
the definitions I have provided. As discussed previously, it would be
interesting to study a system for supporting side-effecting functions (aka
closures) for session channels. In order to achieve this, operational
semantics for GV would need to be defined, and the recent draft by
\citeauthor{Lindley:2014:SPS} may provide some useful insights on how best to
do this~\cite{Lindley:2014:SPS}. I allocated the remaining time (approx. two
months) to perform this extension because I believe it requires the most
development: extending existing definitions to handle side-effecting
functions, defining operational semantics, proving subject reduction and
related properties. Additionally, it will also require a theoretical treatment
prior to undertaking the development task, in contrast to the preceding
development work which mostly utilises results from the literature.

There is a risk of being unable to perform the side-effecting extension as
sketched in \S \ref{sec:approach}. I shall review and update the above plan
throughtout the project as I proceed to the various milestones I have set out,
and if required will alter the above plans if necessary.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\printbibliography

\end{document}
